{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b09e50",
   "metadata": {},
   "source": [
    "# Part 3: Fine-tuning DistilBERT for Fake News Detection\n",
    "\n",
    "In this notebook, I'll build on our previous exploratory data analysis and feature engineering work to fine-tune a DistilBERT model for fake news detection. While our engineered features achieved impressive results, transformer models like DistilBERT can capture more complex linguistic patterns that might further improve performance or provide better generalization to new data.\n",
    "\n",
    "## 1. Setup and Library Installation\n",
    "\n",
    "First, I'll import the necessary libraries and install any missing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7bc895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:52:26.573713Z",
     "iopub.status.busy": "2025-05-06T07:52:26.573455Z",
     "iopub.status.idle": "2025-05-06T07:53:37.427821Z",
     "shell.execute_reply": "2025-05-06T07:53:37.426581Z",
     "shell.execute_reply.started": "2025-05-06T07:52:26.573691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch evaluate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbf200d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:53:37.429596Z",
     "iopub.status.busy": "2025-05-06T07:53:37.429337Z",
     "iopub.status.idle": "2025-05-06T07:54:06.398017Z",
     "shell.execute_reply": "2025-05-06T07:54:06.397351Z",
     "shell.execute_reply.started": "2025-05-06T07:53:37.429572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 07:53:52.728666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746518032.930675      62 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746518032.991943      62 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import Dataset as HFDataset\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f0f8e",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Dataset\n",
    "\n",
    "I'll load the preprocessed datasets from our previous work. If you're running this notebook independently, make sure you have the processed files from Part 2, or run the data preprocessing steps from the previous notebooks first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcd27bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:54:06.399254Z",
     "iopub.status.busy": "2025-05-06T07:54:06.398745Z",
     "iopub.status.idle": "2025-05-06T07:54:08.754697Z",
     "shell.execute_reply": "2025-05-06T07:54:08.754059Z",
     "shell.execute_reply.started": "2025-05-06T07:54:06.399233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (31428, 3)\n",
      "Validation set: (6735, 3)\n",
      "Test set: (6735, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed datasets\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/isot-processed-and-splitted/train_fake_news.csv')\n",
    "    val_df = pd.read_csv('/kaggle/input/isot-processed-and-splitted/val_fake_news.csv') \n",
    "    test_df = pd.read_csv('/kaggle/input/isot-processed-and-splitted/test_fake_news.csv')\n",
    "    \n",
    "    print(f\"Training set: {train_df.shape}\")\n",
    "    print(f\"Validation set: {val_df.shape}\")\n",
    "    print(f\"Test set: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Preprocessed files not found. Please run the data preprocessing from Part 2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b73f2",
   "metadata": {},
   "source": [
    "Let's examine the data format to ensure it's what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2e3e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:54:08.756616Z",
     "iopub.status.busy": "2025-05-06T07:54:08.756237Z",
     "iopub.status.idle": "2025-05-06T07:54:08.777713Z",
     "shell.execute_reply": "2025-05-06T07:54:08.777061Z",
     "shell.execute_reply.started": "2025-05-06T07:54:08.756591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>enhanced_cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump ‘Diversity Council’ Member Threatens to ...</td>\n",
       "      <td>A member of President Trump s Diversity Counci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DID BEYONCE AND JAY Z’s “Vacation” To Communis...</td>\n",
       "      <td>Notorious radical Black Panther and NJ cop kil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Host Calls Out Trump’s Uncle Tom Spokeswo...</td>\n",
       "      <td>Katrina Pierson is a black woman. She is also ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump ‘Diversity Council’ Member Threatens to ...   \n",
       "1  DID BEYONCE AND JAY Z’s “Vacation” To Communis...   \n",
       "2   CNN Host Calls Out Trump’s Uncle Tom Spokeswo...   \n",
       "\n",
       "                               enhanced_cleaned_text  label  \n",
       "0  A member of President Trump s Diversity Counci...      0  \n",
       "1  Notorious radical Black Panther and NJ cop kil...      0  \n",
       "2  Katrina Pierson is a black woman. She is also ...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample of training data:\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65949b",
   "metadata": {},
   "source": [
    "Next, I'll convert our pandas DataFrames to the Hugging Face Dataset format, which is optimized for working with the transformers library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d2803b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:54:08.779480Z",
     "iopub.status.busy": "2025-05-06T07:54:08.778571Z",
     "iopub.status.idle": "2025-05-06T07:54:10.074876Z",
     "shell.execute_reply": "2025-05-06T07:54:10.074207Z",
     "shell.execute_reply.started": "2025-05-06T07:54:08.779447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 31428 examples\n",
      "Validation dataset: 6735 examples\n",
      "Test dataset: 6735 examples\n"
     ]
    }
   ],
   "source": [
    "# Function to convert pandas DataFrames to HuggingFace Datasets\n",
    "def convert_to_hf_dataset(df):\n",
    "    # For DistilBERT, we'll use both title and text\n",
    "    df['text'] = df['title'] + \" \" + df['enhanced_cleaned_text']\n",
    "    \n",
    "    # Convert to HuggingFace Dataset format\n",
    "    dataset = HFDataset.from_pandas(df[['text', 'label']])\n",
    "    return dataset\n",
    "\n",
    "# Convert our datasets\n",
    "train_dataset = convert_to_hf_dataset(train_df)\n",
    "val_dataset = convert_to_hf_dataset(val_df)\n",
    "test_dataset = convert_to_hf_dataset(test_df)\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset)} examples\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} examples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949cf48b",
   "metadata": {},
   "source": [
    "## 3. Prepare Tokenizer and Model\n",
    "\n",
    "Now I'll set up the DistilBERT tokenizer and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc6f858-9f44-406e-ae73-bc01f504677d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:54:10.075860Z",
     "iopub.status.busy": "2025-05-06T07:54:10.075603Z",
     "iopub.status.idle": "2025-05-06T07:54:12.943868Z",
     "shell.execute_reply": "2025-05-06T07:54:12.943269Z",
     "shell.execute_reply.started": "2025-05-06T07:54:10.075840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example in train_dataset: {'text': 'Trump ‘Diversity Council’ Member Threatens to Quit If Trump Ends DACA…Bye, Bye! [Video] A member of President Trump s Diversity Council is threatening to quit because he opposes Trump s cancelation of DACA. Bye Bye!Trump diversity council member tells @Acosta he may quit the council if Trump moves ahead to end DACA CNN Newsroom (@CNNnewsroom) September 4, 2017 I want to remind him and his team that from an economic standpoint, and again, we re business people if you look at this from a purely economic standpoint again, none of these young people gets government benefits of any sorts so they re not costing us anything. They pay over $2 billion in taxes Is anyone else out there sick of the American people being told illegals cost nothing?DACA Will Cost Americans And Their Government A Huge Amount of Money.On average, people with college degrees pay more in taxes than they receive in government benefits. People without a degree consume more taxes than they pay to federal, state and local tax officials.In 2013, a Heritage Foundation study showed that amnesty for 11 million illegals would spike federal spending by $6,300 billion over the next five decades. That is roughly equivalent to $550,000 per illegal, or $10,000 per illegal per year, much of which will be spent when the immigrant becomes eligible for Social Security and Medicare. That cost estimate does not include the extra costs created when immigrants use their new legal powers as a citizen to bring in more low-skilled migrants.If those 3 million DACA people and their parents soon become legal residents or citizens, then Obama s DACA will cost Americans roughly $1,700 billion over the next 50 years, according to Heritage Foundation s numbers.Moreover, the DACA migrants add to the flood of illegal labor that has driven down wages for ordinary Americans, including urban youths and recent immigrants. Currently, Americans lose roughly $500 billion a year from their salaries because of the immigration tax caused by cheap labor according to the academies report.Via: GP', 'label': 0}\n",
      "Text type for first example: <class 'str'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2cd4d6dbb145a3941a23f1ab4c39ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc357f38e8234bea9e14c0f68772e988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b833d8502e443db9f1cf1eff73d23fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check first few examples in your dataset\n",
    "print(\"First example in train_dataset:\", train_dataset[0])\n",
    "\n",
    "# Debug the content types\n",
    "print(\"Text type for first example:\", type(train_dataset[0]['text']))\n",
    "\n",
    "# If needed, clean the dataset before tokenization\n",
    "def clean_dataset(example):\n",
    "    example['text'] = str(example['text']) if example['text'] is not None else \"\"\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(clean_dataset)\n",
    "val_dataset = val_dataset.map(clean_dataset)\n",
    "test_dataset = test_dataset.map(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9cf2857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:54:12.944788Z",
     "iopub.status.busy": "2025-05-06T07:54:12.944581Z",
     "iopub.status.idle": "2025-05-06T07:59:20.008078Z",
     "shell.execute_reply": "2025-05-06T07:59:20.007471Z",
     "shell.execute_reply.started": "2025-05-06T07:54:12.944771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aa55f707ac42ce8b17c3a65894c443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9575ffd9da024895a66b91a7f61a9032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbff8049efd64454871cab59d2521624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f21b6d6ca24c33b56a820d991c256e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0632ee2ca9ba441fb17ef2795914e9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d42ed09eb29447c9b97b2e060cfd135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401b2ae7d80c4667beacc5a2bb250aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_length = 512  # This is the maximum that BERT models can handle\n",
    "\n",
    "# Function to tokenize the dataset - modified to handle potential bad inputs\n",
    "def tokenize_function(examples):\n",
    "    # Convert all text entries to strings and handle potential None values\n",
    "    texts = [str(text) if text is not None else \"\" for text in examples['text']]\n",
    "    \n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=None  # Don't return tensors in batch mode\n",
    "    )\n",
    "\n",
    "# Apply tokenization to our datasets\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch after tokenization\n",
    "train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4670169",
   "metadata": {},
   "source": [
    "## 4. Define Metrics and Evaluation Strategy\n",
    "\n",
    "I'll define our evaluation metrics to track model performance during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8fb6e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:59:20.009236Z",
     "iopub.status.busy": "2025-05-06T07:59:20.008922Z",
     "iopub.status.idle": "2025-05-06T07:59:20.013845Z",
     "shell.execute_reply": "2025-05-06T07:59:20.013170Z",
     "shell.execute_reply.started": "2025-05-06T07:59:20.009188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ddf09",
   "metadata": {},
   "source": [
    "## 5. Initialize Model for Fine-tuning\n",
    "\n",
    "Now I'll initialize the DistilBERT model for sequence classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cabf580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:59:20.014750Z",
     "iopub.status.busy": "2025-05-06T07:59:20.014549Z",
     "iopub.status.idle": "2025-05-06T07:59:21.854116Z",
     "shell.execute_reply": "2025-05-06T07:59:21.853468Z",
     "shell.execute_reply.started": "2025-05-06T07:59:20.014734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33748f06e24e4c42a3d7b9055f428a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2  # Binary classification: 0 for fake, 1 for real\n",
    ")\n",
    "\n",
    "# Move model to device (GPU if available)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba4d6a",
   "metadata": {},
   "source": [
    "## 6. Define Training Arguments and Trainer\n",
    "\n",
    "Next, I'll configure the training parameters and create a Trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507f1fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:59:42.640699Z",
     "iopub.status.busy": "2025-05-06T07:59:42.640120Z",
     "iopub.status.idle": "2025-05-06T07:59:42.683788Z",
     "shell.execute_reply": "2025-05-06T07:59:42.683265Z",
     "shell.execute_reply.started": "2025-05-06T07:59:42.640674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory for model checkpoints\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=100,               # Log every X steps\n",
    "    eval_strategy=\"epoch\",     # Evaluate every epoch\n",
    "    save_strategy=\"epoch\",           # Save model checkpoint every epoch\n",
    "    load_best_model_at_end=True,     # Load the best model at the end\n",
    "    metric_for_best_model=\"f1\",      # Use F1 score to determine the best model\n",
    "    push_to_hub=False,               # Don't push to Hugging Face Hub\n",
    "    report_to=\"none\"                 # Disable reporting to avoid wandb or other services\n",
    ")\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The instantiated model to train\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_tokenized,       # Training dataset\n",
    "    eval_dataset=val_tokenized,          # Evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # The function to compute metrics\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0a10a",
   "metadata": {},
   "source": [
    "## 7. Fine-tune the Model\n",
    "\n",
    "Now I'll fine-tune the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a143610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T07:59:45.273212Z",
     "iopub.status.busy": "2025-05-06T07:59:45.272628Z",
     "iopub.status.idle": "2025-05-06T08:48:27.350083Z",
     "shell.execute_reply": "2025-05-06T08:48:27.349512Z",
     "shell.execute_reply.started": "2025-05-06T07:59:45.273187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5895' max='5895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5895/5895 48:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 48.69 minutes\n"
     ]
    }
   ],
   "source": [
    "# Start the timer to measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time/60:.2f} minutes\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./distilbert-fake-news-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fc168",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance\n",
    "\n",
    "I'll evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1514d047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T08:49:05.644690Z",
     "iopub.status.busy": "2025-05-06T08:49:05.644121Z",
     "iopub.status.idle": "2025-05-06T08:50:03.000743Z",
     "shell.execute_reply": "2025-05-06T08:50:02.999979Z",
     "shell.execute_reply.started": "2025-05-06T08:49:05.644668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.0023615937680006027, 'eval_accuracy': 0.999554565701559, 'eval_f1': 0.999554556431033, 'eval_precision': 0.9995549446870654, 'eval_recall': 0.999554565701559, 'eval_runtime': 57.3478, 'eval_samples_per_second': 117.441, 'eval_steps_per_second': 3.679, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_results = trainer.evaluate(test_tokenized)\n",
    "print(f\"Test results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438610d",
   "metadata": {},
   "source": [
    "Let's also look at the confusion matrix to get a better understanding of the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e2bebc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T08:50:06.039913Z",
     "iopub.status.busy": "2025-05-06T08:50:06.039354Z",
     "iopub.status.idle": "2025-05-06T08:51:06.924900Z",
     "shell.execute_reply": "2025-05-06T08:51:06.924321Z",
     "shell.execute_reply.started": "2025-05-06T08:50:06.039890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3523    0]\n",
      " [   3 3209]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Fake News       1.00      1.00      1.00      3523\n",
      "   Real News       1.00      1.00      1.00      3212\n",
      "\n",
      "    accuracy                           1.00      6735\n",
      "   macro avg       1.00      1.00      1.00      6735\n",
      "weighted avg       1.00      1.00      1.00      6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on the test set\n",
    "test_pred = trainer.predict(test_tokenized)\n",
    "y_preds = np.argmax(test_pred.predictions, axis=1)\n",
    "y_true = test_pred.label_ids\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('DistilBERT Confusion Matrix')\n",
    "plt.savefig('distilbert_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_preds, target_names=['Fake News', 'Real News']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2793a40",
   "metadata": {},
   "source": [
    "## 9. Analyze Misclassified Examples\n",
    "\n",
    "Let's analyze some misclassified examples to understand where the model struggles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cccf22b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T08:52:12.716052Z",
     "iopub.status.busy": "2025-05-06T08:52:12.715224Z",
     "iopub.status.idle": "2025-05-06T08:52:12.728489Z",
     "shell.execute_reply": "2025-05-06T08:52:12.727666Z",
     "shell.execute_reply.started": "2025-05-06T08:52:12.716028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified examples: 3\n",
      "\n",
      "Sample of misclassified examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump on Twitter (August 10): Mitch McConnell</td>\n",
       "      <td>Real</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uber joins forces with global public transport...</td>\n",
       "      <td>Real</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Gates of Hell': Iraqi army says fighting near...</td>\n",
       "      <td>Real</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title True Label  \\\n",
       "0      Trump on Twitter (August 10): Mitch McConnell       Real   \n",
       "1  Uber joins forces with global public transport...       Real   \n",
       "2  'Gates of Hell': Iraqi army says fighting near...       Real   \n",
       "\n",
       "  Predicted Label  \n",
       "0            Fake  \n",
       "1            Fake  \n",
       "2            Fake  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get indices of misclassified examples\n",
    "misclassified_indices = np.where(y_preds != y_true)[0]\n",
    "print(f\"Number of misclassified examples: {len(misclassified_indices)}\")\n",
    "\n",
    "# If there are misclassifications, analyze a few\n",
    "if len(misclassified_indices) > 0:\n",
    "    # Get the original text and predictions\n",
    "    misclassified_texts = []\n",
    "    for idx in misclassified_indices[:5]:  # Examine up to 5 examples\n",
    "        # Convert numpy.int64 to Python int\n",
    "        idx_int = int(idx)\n",
    "        \n",
    "        # Now use the converted index\n",
    "        original_idx = test_dataset[idx_int]['__index_level_0__'] if '__index_level_0__' in test_dataset[idx_int] else idx_int\n",
    "        \n",
    "        text = test_df.iloc[original_idx]['title']\n",
    "        true_label = \"Real\" if y_true[idx] == 1 else \"Fake\"\n",
    "        pred_label = \"Real\" if y_preds[idx] == 1 else \"Fake\"\n",
    "        \n",
    "        misclassified_texts.append({\n",
    "            'Title': text,\n",
    "            'True Label': true_label,\n",
    "            'Predicted Label': pred_label\n",
    "        })\n",
    "    \n",
    "    # Display misclassified examples\n",
    "    print(\"\\nSample of misclassified examples:\")\n",
    "    display(pd.DataFrame(misclassified_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c1c5d",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Next Steps\n",
    "\n",
    "In this notebook, I've fine-tuned a DistilBERT model for fake news detection on the ISOT dataset. Here are the key findings:\n",
    "\n",
    "1. **Performance Comparison**: The DistilBERT model achieved [insert accuracy here] accuracy, which is [better/worse/comparable] to our previous models using engineered features (99.98%) and TF-IDF (98.4%).\n",
    "\n",
    "2. **Training Efficiency**: Despite being more complex, DistilBERT is quite efficient for fine-tuning, with the process completing in approximately [insert time] minutes.\n",
    "\n",
    "3. **Error Analysis**: Analysis of misclassified examples shows that DistilBERT struggles with [insert observations about errors].\n",
    "\n",
    "4. **Generalization Potential**: Transformer models like DistilBERT likely have better generalization capabilities to new and unseen fake news, as they understand context and semantic meaning more deeply.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Experiment with Other Pretrained Models**: Try fine-tuning larger models like BERT-base or RoBERTa to see if they offer improvements.\n",
    "\n",
    "2. **Combined Approach**: Develop an ensemble model that combines our engineered features with transformer-based features.\n",
    "\n",
    "3. **External Validation**: Test the model on different fake news datasets to evaluate cross-dataset generalization.\n",
    "\n",
    "4. **Model Explainability**: Implement techniques like LIME or SHAP to understand which parts of text the model relies on for classification.\n",
    "\n",
    "5. **Deployment Considerations**: Optimize the model for inference time if it's to be used in a real-time application.\n",
    "\n",
    "The transformer-based approach offers a powerful complement to our feature engineering work, potentially providing better generalization to evolving fake news tactics and new domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f344ff",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive approach to fine-tuning DistilBERT for fake news detection, building on our previous work of exploratory data analysis and feature engineering. The transformer-based approach captures complex linguistic patterns that may complement our engineered features and improve model robustness."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7338050,
     "sourceId": 11691225,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
