{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3328447",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# TinyBERT for Fake News Detection - Enhanced Training and Evaluation\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook demonstrates how to finetune TinyBERT for detecting fake news using the WELFake dataset with improved training strategies and rigorous evaluation methods. TinyBERT is an efficient and lightweight transformer model that uses knowledge distillation to achieve performance comparable to larger models while requiring significantly fewer computational resources.\n",
    "\n",
    "TinyBERT has approximately 15 million parameters, making it about 7.5x smaller than BERT-base, while maintaining strong performance on natural language understanding tasks. This efficiency makes it an excellent candidate for fake news detection applications that may need to run on resource-constrained environments like mobile devices or edge computing platforms.\n",
    "\n",
    "### What's New in This Enhanced Version\n",
    "\n",
    "We've made several critical improvements to ensure more reliable and robust results:\n",
    "\n",
    "1. **Optimized Hyperparameters**: We'll use TinyBERT-specific learning rates and training strategies based on the model's architecture\n",
    "2. **Multiple Training Runs**: Instead of a single train/test split, we'll perform multiple runs to establish confidence intervals\n",
    "3. **K-Fold Cross-Validation**: We'll implement 5-fold cross-validation to ensure every sample is used for both training and testing\n",
    "4. **Improved Training Strategy**: Better early stopping patience, learning rate scheduling, and regularization techniques\n",
    "\n",
    "These changes will give us a much more accurate picture of TinyBERT's true capabilities for fake news detection.\n",
    "\n",
    "## 2. Environment Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment. We'll need PyTorch for deep learning, Hugging Face Transformers for the model, and various utilities for data processing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efd4133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:15.981002Z",
     "iopub.status.busy": "2025-05-22T17:37:15.980682Z",
     "iopub.status.idle": "2025-05-22T17:37:19.064836Z",
     "shell.execute_reply": "2025-05-22T17:37:19.064154Z",
     "shell.execute_reply.started": "2025-05-22T17:37:15.980973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import basic utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3f582",
   "metadata": {},
   "source": [
    "### PyTorch and System Libraries\n",
    "We import PyTorch for our deep learning framework and set up system utilities for file management and timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30e9f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:19.066127Z",
     "iopub.status.busy": "2025-05-22T17:37:19.065829Z",
     "iopub.status.idle": "2025-05-22T17:37:23.047128Z",
     "shell.execute_reply": "2025-05-22T17:37:23.046568Z",
     "shell.execute_reply.started": "2025-05-22T17:37:19.066109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13b4e9",
   "metadata": {},
   "source": [
    "### Hugging Face Libraries\n",
    "The Transformers library provides pre-trained models and utilities for fine-tuning, while the Datasets library helps with efficient data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef442c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:23.048082Z",
     "iopub.status.busy": "2025-05-22T17:37:23.047779Z",
     "iopub.status.idle": "2025-05-22T17:37:46.046048Z",
     "shell.execute_reply": "2025-05-22T17:37:46.045384Z",
     "shell.execute_reply.started": "2025-05-22T17:37:23.048066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:37:31.937352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747935452.120091      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747935452.173562      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import Hugging Face libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import get_scheduler\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc818db1",
   "metadata": {},
   "source": [
    "### Evaluation Libraries\n",
    "These libraries will help us measure our model's performance with standard metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6688b182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.047555Z",
     "iopub.status.busy": "2025-05-22T17:37:46.046866Z",
     "iopub.status.idle": "2025-05-22T17:37:46.067341Z",
     "shell.execute_reply": "2025-05-22T17:37:46.066808Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.047500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import evaluation libraries\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc74fe5",
   "metadata": {},
   "source": [
    "### Utilities for Clean Output\n",
    "We'll suppress warnings to keep our notebook clean and focused on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464b40b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.069463Z",
     "iopub.status.busy": "2025-05-22T17:37:46.069063Z",
     "iopub.status.idle": "2025-05-22T17:37:46.072554Z",
     "shell.execute_reply": "2025-05-22T17:37:46.071853Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.069446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cf28e",
   "metadata": {},
   "source": [
    "### Setting Up Reproducibility\n",
    "Setting a random seed ensures our results are reproducible across different runs. However, for multiple runs, we'll use different seeds to get a better estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1e8599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.073649Z",
     "iopub.status.busy": "2025-05-22T17:37:46.073371Z",
     "iopub.status.idle": "2025-05-22T17:37:46.084914Z",
     "shell.execute_reply": "2025-05-22T17:37:46.084238Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.073624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"\n",
    "    Set seeds for all random number generators to ensure reproducibility.\n",
    "    This affects random, numpy, PyTorch CPU and GPU operations.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d76888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.085789Z",
     "iopub.status.busy": "2025-05-22T17:37:46.085550Z",
     "iopub.status.idle": "2025-05-22T17:37:46.099424Z",
     "shell.execute_reply": "2025-05-22T17:37:46.098742Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.085774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply seed for initial setup\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8468b",
   "metadata": {},
   "source": [
    "### Checking Hardware Availability\n",
    "We'll check if a GPU is available to accelerate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5cf665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.100434Z",
     "iopub.status.busy": "2025-05-22T17:37:46.100254Z",
     "iopub.status.idle": "2025-05-22T17:37:46.104371Z",
     "shell.execute_reply": "2025-05-22T17:37:46.103780Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.100421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9c36d",
   "metadata": {},
   "source": [
    "## 3. Loading and Exploring the Dataset\n",
    "\n",
    "The WELFake dataset combines real and fake news articles from multiple sources. Let's load it and understand its structure and distribution before proceeding with model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0ec6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:46.105228Z",
     "iopub.status.busy": "2025-05-22T17:37:46.105044Z",
     "iopub.status.idle": "2025-05-22T17:37:51.907165Z",
     "shell.execute_reply": "2025-05-22T17:37:51.906570Z",
     "shell.execute_reply.started": "2025-05-22T17:37:46.105214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('/kaggle/input/welfake-cleaned/WELFake_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f466b",
   "metadata": {},
   "source": [
    "### Dataset Size and Shape\n",
    "First, let's check the overall size of the dataset to understand how much data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11dacd76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:51.908125Z",
     "iopub.status.busy": "2025-05-22T17:37:51.907928Z",
     "iopub.status.idle": "2025-05-22T17:37:51.912611Z",
     "shell.execute_reply": "2025-05-22T17:37:51.911728Z",
     "shell.execute_reply.started": "2025-05-22T17:37:51.908110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (71537, 10)\n",
      "\n",
      "Column names: ['Unnamed: 0', 'title', 'text', 'label', 'title_length', 'text_length', 'word_count', 'title_has_allcaps', 'title_exclamation', 'title_question']\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97a830",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "It's important to check the balance between real and fake news articles to ensure our model doesn't develop bias toward the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9833f6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:51.914101Z",
     "iopub.status.busy": "2025-05-22T17:37:51.913423Z",
     "iopub.status.idle": "2025-05-22T17:37:51.932109Z",
     "shell.execute_reply": "2025-05-22T17:37:51.931581Z",
     "shell.execute_reply.started": "2025-05-22T17:37:51.914082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "label\n",
      "1    51.04\n",
      "0    48.96\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "class_distribution = df['label'].value_counts(normalize=True).mul(100).round(2)\n",
    "print(f\"Class distribution:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d622b",
   "metadata": {},
   "source": [
    "### Visualizing the Class Distribution\n",
    "A visual representation helps us better understand the dataset balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729c24ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:51.933170Z",
     "iopub.status.busy": "2025-05-22T17:37:51.932845Z",
     "iopub.status.idle": "2025-05-22T17:37:52.170421Z",
     "shell.execute_reply": "2025-05-22T17:37:52.169701Z",
     "shell.execute_reply.started": "2025-05-22T17:37:51.933151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='label', data=df, palette='viridis')\n",
    "plt.title('Distribution of Real vs. Fake News')\n",
    "plt.xlabel('Label (0: Real, 1: Fake)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():,}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c6aa02",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "For transformer-based models like TinyBERT, we need to carefully prepare our input data. We'll combine the article title and text to provide complete information to the model.\n",
    "\n",
    "### Combining Title and Text\n",
    "For news articles, both the headline and body contain important information. By combining them, we provide the model with the complete content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5838cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.171577Z",
     "iopub.status.busy": "2025-05-22T17:37:52.171219Z",
     "iopub.status.idle": "2025-05-22T17:37:52.567137Z",
     "shell.execute_reply": "2025-05-22T17:37:52.566388Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.171548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine title and text\n",
    "df['full_text'] = df['title'] + \" \" + df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95c921",
   "metadata": {},
   "source": [
    "## 5. Enhanced Training Strategy with Multiple Runs\n",
    "\n",
    "### Understanding Why Multiple Runs Matter\n",
    "\n",
    "When we train a neural network, many factors introduce randomness: the initial weights, the order of data batches, dropout patterns, and even GPU operations. A single training run might give us a lucky (or unlucky) result that doesn't represent the model's true performance. By training multiple times with different random seeds, we can establish confidence intervals and understand the model's expected performance range.\n",
    "\n",
    "This is similar to measuring someone's running speed - you wouldn't time them just once and call it their definitive speed. You'd have them run multiple times and report their average time with a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f03640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.570216Z",
     "iopub.status.busy": "2025-05-22T17:37:52.569976Z",
     "iopub.status.idle": "2025-05-22T17:37:52.577015Z",
     "shell.execute_reply": "2025-05-22T17:37:52.576304Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.570198Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_multiple_training_runs(df, n_runs=5):\n",
    "    \"\"\"\n",
    "    Perform multiple training runs with different random seeds to establish\n",
    "    confidence intervals for model performance.\n",
    "    \n",
    "    Args:\n",
    "        df: The dataframe containing our data\n",
    "        n_runs: Number of independent training runs\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing results from all runs\n",
    "    \"\"\"\n",
    "    all_results = defaultdict(list)\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting Run {run + 1} of {n_runs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Set a different seed for each run\n",
    "        run_seed = 42 + run * 100  # Ensures different but reproducible seeds\n",
    "        set_seed(run_seed)\n",
    "        \n",
    "        # Create train/val/test split for this run\n",
    "        train_val_df, test_df = train_test_split(\n",
    "            df, test_size=0.15, stratify=df['label'], random_state=run_seed\n",
    "        )\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_val_df, test_size=0.1765, stratify=train_val_df['label'], \n",
    "            random_state=run_seed\n",
    "        )\n",
    "        \n",
    "        # Store the results from this run\n",
    "        run_results = train_and_evaluate_single_run(\n",
    "            train_df, val_df, test_df, run_seed\n",
    "        )\n",
    "        \n",
    "        # Aggregate results\n",
    "        for metric, value in run_results.items():\n",
    "            all_results[metric].append(value)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5863a",
   "metadata": {},
   "source": [
    "## 6. TinyBERT-Specific Hyperparameter Configuration\n",
    "\n",
    "### Why TinyBERT Needs Special Treatment\n",
    "\n",
    "TinyBERT was created through a sophisticated knowledge distillation process where it learned to mimic BERT's behavior while being much smaller. This distillation process makes TinyBERT different from models that were simply trained from scratch with fewer parameters. The distilled knowledge allows TinyBERT to handle slightly higher learning rates than you might expect for such a small model, but it also benefits from specific training strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4edb569c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:43:02.346715Z",
     "iopub.status.busy": "2025-05-22T17:43:02.346207Z",
     "iopub.status.idle": "2025-05-22T17:43:02.352998Z",
     "shell.execute_reply": "2025-05-22T17:43:02.352293Z",
     "shell.execute_reply.started": "2025-05-22T17:43:02.346688Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tinybert_optimized_training_args(output_dir, train_dataset_size, batch_size=16):\n",
    "    \"\"\"\n",
    "    Get training arguments specifically optimized for TinyBERT architecture.\n",
    "    \n",
    "    These hyperparameters are based on:\n",
    "    1. TinyBERT's distilled nature allowing for higher learning rates\n",
    "    2. The model's smaller size requiring less regularization\n",
    "    3. Empirical findings from the original TinyBERT paper\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate training steps for learning rate scheduler\n",
    "    num_epochs = 5\n",
    "    steps_per_epoch = train_dataset_size // batch_size\n",
    "    if steps_per_epoch % 2 != 0:\n",
    "        steps_per_epoch += 1\n",
    "    total_training_steps = steps_per_epoch * num_epochs\n",
    "    \n",
    "    # Warmup should be about 10% of total training\n",
    "    warmup_steps = int(0.1 * total_training_steps)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        \n",
    "        # Evaluation and saving strategy\n",
    "        eval_strategy=\"steps\",           # Evaluate more frequently\n",
    "        eval_steps=steps_per_epoch // 2, # Evaluate twice per epoch\n",
    "        save_strategy=\"steps\",           \n",
    "        save_steps=steps_per_epoch,      # Save after each epoch\n",
    "        \n",
    "        # Learning rate configuration\n",
    "        learning_rate=1e-4,              # Higher than typical BERT (5e-5) due to distillation\n",
    "        warmup_steps=warmup_steps,       # Gradual warmup\n",
    "        \n",
    "        # Batch size and gradient accumulation\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=64,   # Larger for faster evaluation\n",
    "        gradient_accumulation_steps=2,    # Effective batch size of 32\n",
    "        \n",
    "        # Training epochs and patience\n",
    "        num_train_epochs=num_epochs,\n",
    "        \n",
    "        # Regularization\n",
    "        weight_decay=0.01,               # Standard weight decay\n",
    "        adam_epsilon=1e-6,               # Slightly smaller epsilon for stability\n",
    "        max_grad_norm=1.0,               # Gradient clipping\n",
    "        \n",
    "        # Model selection\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # Efficiency settings\n",
    "        fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
    "        dataloader_num_workers=2,\n",
    "        \n",
    "        # Logging\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",  # Disable cloud logging for now\n",
    "        \n",
    "        # Disable certain features for clarity\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=3,  # Keep only best 3 checkpoints\n",
    "        \n",
    "        # Random seed handled externally\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e895d91",
   "metadata": {},
   "source": [
    "## 7. Implementing Custom Learning Rate Schedule\n",
    "\n",
    "### The Importance of Learning Rate Scheduling\n",
    "\n",
    "Think of learning rate scheduling like teaching someone to write - you start with big, bold strokes to get the general shape right, then gradually make smaller, more precise adjustments. For TinyBERT, we'll use a cosine schedule with warmup, which has been shown to work particularly well for distilled models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a320ef13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.589623Z",
     "iopub.status.busy": "2025-05-22T17:37:52.589351Z",
     "iopub.status.idle": "2025-05-22T17:37:52.603004Z",
     "shell.execute_reply": "2025-05-22T17:37:52.602443Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.589600Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tinybert_optimizer_and_scheduler(model, training_args, num_training_steps):\n",
    "    \"\"\"\n",
    "    Create optimizer and learning rate scheduler optimized for TinyBERT.\n",
    "    \n",
    "    We use:\n",
    "    1. AdamW optimizer with corrected weight decay\n",
    "    2. Cosine schedule with warmup for smooth training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate parameters that should and shouldn't have weight decay\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() \n",
    "                      if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": training_args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() \n",
    "                      if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=training_args.learning_rate,\n",
    "        eps=training_args.adam_epsilon,\n",
    "        betas=(0.9, 0.98)  # Slightly different from default for TinyBERT\n",
    "    )\n",
    "    \n",
    "    # Create learning rate scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=training_args.warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    return optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5696d22",
   "metadata": {},
   "source": [
    "## 8. Enhanced Early Stopping Configuration\n",
    "\n",
    "### Why Our Previous Early Stopping Was Too Aggressive\n",
    "\n",
    "With a patience of 2, we were essentially giving up after just two evaluations without improvement. But transformer training often shows a \"double descent\" pattern - performance might plateau or even slightly decrease before improving again. For TinyBERT, we'll use a more patient approach that considers the overall trend rather than reacting to short-term fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35df3fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.603908Z",
     "iopub.status.busy": "2025-05-22T17:37:52.603675Z",
     "iopub.status.idle": "2025-05-22T17:37:52.614399Z",
     "shell.execute_reply": "2025-05-22T17:37:52.613763Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.603892Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_enhanced_early_stopping_callback():\n",
    "    \"\"\"\n",
    "    Create an early stopping callback with TinyBERT-appropriate patience.\n",
    "    \n",
    "    We use patience of 5 evaluation steps (2.5 epochs with our eval strategy)\n",
    "    to allow the model to work through temporary plateaus.\n",
    "    \"\"\"\n",
    "    return EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,  # Much more patient than before\n",
    "        early_stopping_threshold=0.001  # Minimum improvement to reset patience\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c47a0",
   "metadata": {},
   "source": [
    "## 9. Single Run Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90a3de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.615425Z",
     "iopub.status.busy": "2025-05-22T17:37:52.615204Z",
     "iopub.status.idle": "2025-05-22T17:37:52.632012Z",
     "shell.execute_reply": "2025-05-22T17:37:52.631312Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.615409Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_single_run(train_df, val_df, test_df, seed):\n",
    "    \"\"\"\n",
    "    Perform a single training run with optimized hyperparameters.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing test metrics from this run\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Convert to Hugging Face datasets\n",
    "    train_dataset = Dataset.from_pandas(train_df[['full_text', 'label']])\n",
    "    val_dataset = Dataset.from_pandas(val_df[['full_text', 'label']])\n",
    "    test_dataset = Dataset.from_pandas(test_df[['full_text', 'label']])\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "    \n",
    "    # Define tokenization function\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"full_text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    # Set format\n",
    "    tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    tokenized_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"huawei-noah/TinyBERT_General_4L_312D\",\n",
    "        num_labels=2\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define metrics computation\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels, predictions, average='weighted'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "    \n",
    "    # Get optimized training arguments\n",
    "    output_dir = f\"./results/tinybert_welfake_run_{seed}\"\n",
    "    training_args = get_tinybert_optimized_training_args(\n",
    "        output_dir, \n",
    "        len(tokenized_train)\n",
    "    )\n",
    "    \n",
    "    # Create trainer with enhanced configuration\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[create_enhanced_early_stopping_callback()]\n",
    "    )\n",
    "    \n",
    "    # Custom optimizer and scheduler\n",
    "    num_training_steps = len(tokenized_train) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "    optimizer, lr_scheduler = create_tinybert_optimizer_and_scheduler(\n",
    "        model, training_args, num_training_steps\n",
    "    )\n",
    "    trainer.optimizer = optimizer\n",
    "    trainer.lr_scheduler = lr_scheduler\n",
    "    \n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    train_result = trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Training completed in {train_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_results = trainer.evaluate(tokenized_test)\n",
    "    \n",
    "    # Get predictions for confusion matrix\n",
    "    predictions = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(predictions.predictions, axis=1)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(predictions.label_ids, preds)\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'accuracy': test_results['eval_accuracy'],\n",
    "        'precision': test_results['eval_precision'],\n",
    "        'recall': test_results['eval_recall'],\n",
    "        'f1': test_results['eval_f1'],\n",
    "        'train_time': train_time,\n",
    "        'confusion_matrix': cm,\n",
    "        'full_results': test_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6189c",
   "metadata": {},
   "source": [
    "## 10. K-Fold Cross-Validation Implementation\n",
    "\n",
    "### Why K-Fold Cross-Validation Matters\n",
    "\n",
    "K-fold cross-validation ensures that every single sample in our dataset gets to be in the test set exactly once. This gives us a much more complete picture of our model's performance than a single train/test split. It's like having every student in a class take turns being the exam writer - you get a full assessment of everyone's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a03172a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.633032Z",
     "iopub.status.busy": "2025-05-22T17:37:52.632746Z",
     "iopub.status.idle": "2025-05-22T17:37:52.646182Z",
     "shell.execute_reply": "2025-05-22T17:37:52.645572Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.633009Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_kfold_cross_validation(df, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for more robust evaluation.\n",
    "    \n",
    "    This is computationally expensive but gives us the most reliable\n",
    "    estimate of model performance.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X = df['full_text'].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Use StratifiedKFold to maintain class balance in each fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Fold {fold + 1} of {n_splits}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create fold datasets\n",
    "        fold_train_df = df.iloc[train_idx]\n",
    "        fold_test_df = df.iloc[test_idx]\n",
    "        \n",
    "        # Further split training into train/val\n",
    "        fold_train_df, fold_val_df = train_test_split(\n",
    "            fold_train_df, test_size=0.15, stratify=fold_train_df['label'], \n",
    "            random_state=42 + fold\n",
    "        )\n",
    "        \n",
    "        # Train and evaluate on this fold\n",
    "        fold_result = train_and_evaluate_single_run(\n",
    "            fold_train_df, fold_val_df, fold_test_df, seed=42 + fold\n",
    "        )\n",
    "        \n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        print(f\"\\nFold {fold + 1} Results:\")\n",
    "        print(f\"Accuracy: {fold_result['accuracy']:.4f}\")\n",
    "        print(f\"F1 Score: {fold_result['f1']:.4f}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adec2f",
   "metadata": {},
   "source": [
    "## 11. Results Analysis and Visualization Functions\n",
    "\n",
    "### Making Sense of Multiple Runs\n",
    "\n",
    "When we have results from multiple runs, we need to present them in a way that shows both the average performance and the variability. This tells us not just how good the model is, but how consistent it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d09129fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.647205Z",
     "iopub.status.busy": "2025-05-22T17:37:52.646950Z",
     "iopub.status.idle": "2025-05-22T17:37:52.661964Z",
     "shell.execute_reply": "2025-05-22T17:37:52.661240Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.647183Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_multiple_run_results(results_dict):\n",
    "    \"\"\"\n",
    "    Analyze and visualize results from multiple training runs.\n",
    "    \"\"\"\n",
    "    # Calculate statistics\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    stats = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        values = results_dict[metric]\n",
    "        stats[metric] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values),\n",
    "            'min': np.min(values),\n",
    "            'max': np.max(values),\n",
    "            'values': values\n",
    "        }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nModel Performance Summary (Multiple Runs):\")\n",
    "    print(\"=\" * 60)\n",
    "    for metric in metrics:\n",
    "        mean = stats[metric]['mean']\n",
    "        std = stats[metric]['std']\n",
    "        print(f\"{metric.capitalize()}: {mean:.4f} ± {std:.4f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        values = stats[metric]['values']\n",
    "        \n",
    "        # Box plot with individual points\n",
    "        ax.boxplot(values, vert=True, patch_artist=True,\n",
    "                  boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                  medianprops=dict(color='red', linewidth=2))\n",
    "        ax.scatter(np.ones(len(values)), values, alpha=0.6, s=50)\n",
    "        \n",
    "        # Add mean line\n",
    "        ax.axhline(y=stats[metric]['mean'], color='green', \n",
    "                  linestyle='--', label=f'Mean: {stats[metric][\"mean\"]:.4f}')\n",
    "        \n",
    "        ax.set_ylabel(metric.capitalize())\n",
    "        ax.set_title(f'{metric.capitalize()} Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb914aea",
   "metadata": {},
   "source": [
    "## 12. Confidence Interval Calculation\n",
    "\n",
    "### Understanding Confidence Intervals\n",
    "\n",
    "A confidence interval tells us the range where we expect the true performance to lie. If we say \"95% confidence interval\", we mean that if we repeated this entire experiment many times, 95% of the time the true performance would fall within this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4c4d685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.662975Z",
     "iopub.status.busy": "2025-05-22T17:37:52.662723Z",
     "iopub.status.idle": "2025-05-22T17:37:52.675929Z",
     "shell.execute_reply": "2025-05-22T17:37:52.675237Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.662954Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_confidence_intervals(values, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate confidence intervals for a set of values.\n",
    "    \n",
    "    We use the t-distribution for small sample sizes (n < 30).\n",
    "    \"\"\"\n",
    "    from scipy import stats as scipy_stats\n",
    "    \n",
    "    n = len(values)\n",
    "    mean = np.mean(values)\n",
    "    std_err = scipy_stats.sem(values)  # Standard error of the mean\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    ci = scipy_stats.t.interval(confidence, n-1, loc=mean, scale=std_err)\n",
    "    \n",
    "    return mean, ci[0], ci[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a0f2b",
   "metadata": {},
   "source": [
    "## 13. Main Execution Pipeline\n",
    "\n",
    "### Bringing It All Together\n",
    "\n",
    "Now we'll create the main execution pipeline that runs all our enhanced training and evaluation procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c47e51a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:37:52.676941Z",
     "iopub.status.busy": "2025-05-22T17:37:52.676738Z",
     "iopub.status.idle": "2025-05-22T17:37:52.690865Z",
     "shell.execute_reply": "2025-05-22T17:37:52.690067Z",
     "shell.execute_reply.started": "2025-05-22T17:37:52.676927Z"
    }
   },
   "outputs": [],
   "source": [
    "def main_enhanced_training_pipeline():\n",
    "    \"\"\"\n",
    "    Execute the complete enhanced training and evaluation pipeline.\n",
    "    \"\"\"\n",
    "    print(\"Starting Enhanced TinyBERT Training Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('/kaggle/input/welfake-cleaned/WELFake_cleaned.csv')\n",
    "    df['full_text'] = df['title'] + \" \" + df['text']\n",
    "    \n",
    "    # 1. Perform multiple training runs\n",
    "    print(\"\\nPhase 1: Multiple Training Runs\")\n",
    "    print(\"-\" * 40)\n",
    "    multiple_run_results = perform_multiple_training_runs(df, n_runs=5)\n",
    "    \n",
    "    # Analyze multiple run results\n",
    "    run_stats = analyze_multiple_run_results(multiple_run_results)\n",
    "    \n",
    "    # 2. Perform k-fold cross-validation (optional, computationally expensive)\n",
    "    print(\"\\nPhase 2: K-Fold Cross-Validation\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Note: This is computationally expensive. Set perform_kfold=False to skip.\")\n",
    "    \n",
    "    perform_kfold = False  # Set to True if you want to run k-fold CV\n",
    "    \n",
    "    if perform_kfold:\n",
    "        kfold_results = perform_kfold_cross_validation(df, n_splits=5)\n",
    "        \n",
    "        # Extract metrics from k-fold results\n",
    "        kfold_metrics = defaultdict(list)\n",
    "        for fold_result in kfold_results:\n",
    "            for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "                kfold_metrics[metric].append(fold_result[metric])\n",
    "        \n",
    "        # Analyze k-fold results\n",
    "        print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "        print(\"=\" * 60)\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "            values = kfold_metrics[metric]\n",
    "            mean, ci_low, ci_high = calculate_confidence_intervals(values)\n",
    "            print(f\"{metric.capitalize()}: {mean:.4f} (95% CI: [{ci_low:.4f}, {ci_high:.4f}])\")\n",
    "    \n",
    "    # 3. Create final summary report\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL SUMMARY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Report multiple run results with confidence intervals\n",
    "    print(\"\\nMultiple Training Runs (n=5):\")\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        values = multiple_run_results[metric]\n",
    "        mean, ci_low, ci_high = calculate_confidence_intervals(values)\n",
    "        print(f\"{metric.capitalize()}: {mean:.4f} (95% CI: [{ci_low:.4f}, {ci_high:.4f}])\")\n",
    "    \n",
    "    # Training time analysis\n",
    "    train_times = multiple_run_results['train_time']\n",
    "    mean_time = np.mean(train_times) / 60  # Convert to minutes\n",
    "    std_time = np.std(train_times) / 60\n",
    "    print(f\"\\nAverage Training Time: {mean_time:.2f} ± {std_time:.2f} minutes\")\n",
    "    \n",
    "    return multiple_run_results, run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b15d63",
   "metadata": {},
   "source": [
    "## 14. Execute the Enhanced Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41ea1149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:43:28.233960Z",
     "iopub.status.busy": "2025-05-22T17:43:28.233376Z",
     "iopub.status.idle": "2025-05-22T20:00:07.461676Z",
     "shell.execute_reply": "2025-05-22T20:00:07.460423Z",
     "shell.execute_reply.started": "2025-05-22T17:43:28.233935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Enhanced TinyBERT Training Pipeline\n",
      "============================================================\n",
      "\n",
      "Phase 1: Multiple Training Runs\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "Starting Run 1 of 5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20015366e1f542338dde5c8046fe6add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cada2757d08a4025bdb6a2237cdc0d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed920aa2dd7b45e1aae11cbfb563ba7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 24:57, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.131314</td>\n",
       "      <td>0.987236</td>\n",
       "      <td>0.987275</td>\n",
       "      <td>0.987236</td>\n",
       "      <td>0.987237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.105682</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>0.992176</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>0.992174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.00 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Run 2 of 5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741c94d6881242bbb2307203000b9d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caa31ee11f043ac938123399ca6574c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3a6a610a544c7aa632ba11e8991a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 25:04, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.054535</td>\n",
       "      <td>0.988913</td>\n",
       "      <td>0.988995</td>\n",
       "      <td>0.988913</td>\n",
       "      <td>0.988911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.089513</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.992490</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.992452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.10 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Run 3 of 5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5d78243ff941f0b6871147223a0435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d4a655009a49d283d3cbad4d85099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8809742dfa334a97b0db662f41831c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 25:08, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>0.205296</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.974768</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.973818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.115138</td>\n",
       "      <td>0.991056</td>\n",
       "      <td>0.991107</td>\n",
       "      <td>0.991056</td>\n",
       "      <td>0.991056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.17 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Run 4 of 5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f1577ab964b76ae9932b995e605f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cf33bd9e384a0c92fd23e58ad6582e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbd6d7a90284da2a62bf41b11e31e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 25:15, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.059117</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.986673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.168120</td>\n",
       "      <td>0.987981</td>\n",
       "      <td>0.988130</td>\n",
       "      <td>0.987981</td>\n",
       "      <td>0.987978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.28 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Run 5 of 5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dcb7544c4e4a25b9de9086c4f5152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eda8bcac8cd46029bc38e130adf9700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb64407f038c4fb49160011c0e9ad931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 25:16, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.082648</td>\n",
       "      <td>0.987888</td>\n",
       "      <td>0.987913</td>\n",
       "      <td>0.987888</td>\n",
       "      <td>0.987887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.134198</td>\n",
       "      <td>0.989192</td>\n",
       "      <td>0.989287</td>\n",
       "      <td>0.989192</td>\n",
       "      <td>0.989190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.30 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary (Multiple Runs):\n",
      "============================================================\n",
      "Accuracy: 0.9919 ± 0.0014\n",
      "Precision: 0.9919 ± 0.0014\n",
      "Recall: 0.9919 ± 0.0014\n",
      "F1: 0.9919 ± 0.0014\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: K-Fold Cross-Validation\n",
      "----------------------------------------\n",
      "Note: This is computationally expensive. Set perform_kfold=False to skip.\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY REPORT\n",
      "============================================================\n",
      "\n",
      "Multiple Training Runs (n=5):\n",
      "Accuracy: 0.9919 (95% CI: [0.9899, 0.9939])\n",
      "Precision: 0.9919 (95% CI: [0.9900, 0.9939])\n",
      "Recall: 0.9919 (95% CI: [0.9899, 0.9939])\n",
      "F1: 0.9919 (95% CI: [0.9899, 0.9939])\n",
      "\n",
      "Average Training Time: 25.17 ± 0.11 minutes\n"
     ]
    }
   ],
   "source": [
    "# Run the enhanced training pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    results, stats = main_enhanced_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf72837",
   "metadata": {},
   "source": [
    "## 15. Save Results for Future Analysis\n",
    "\n",
    "### Preserving Our Hard Work\n",
    "\n",
    "After all this computation, we want to save our results so we can analyze them later without having to retrain everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c374b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T20:01:44.373141Z",
     "iopub.status.busy": "2025-05-22T20:01:44.372249Z",
     "iopub.status.idle": "2025-05-22T20:01:44.378176Z",
     "shell.execute_reply": "2025-05-22T20:01:44.377372Z",
     "shell.execute_reply.started": "2025-05-22T20:01:44.373109Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_enhanced_results(results, stats, filename='tinybert_enhanced_results.pkl'):\n",
    "    \"\"\"\n",
    "    Save the results of our enhanced training pipeline.\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    results_package = {\n",
    "        'multiple_run_results': results,\n",
    "        'statistics': stats,\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_name': 'TinyBERT',\n",
    "        'dataset': 'WELFake'\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results_package, f)\n",
    "    \n",
    "    print(f\"\\nResults saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf43aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T20:01:44.379647Z",
     "iopub.status.busy": "2025-05-22T20:01:44.379409Z",
     "iopub.status.idle": "2025-05-22T20:01:44.394907Z",
     "shell.execute_reply": "2025-05-22T20:01:44.394207Z",
     "shell.execute_reply.started": "2025-05-22T20:01:44.379631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to tinybert_enhanced_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the results\n",
    "save_enhanced_results(results, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0a8e2a-4c4f-4a34-8a26-60a48ad2f22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T20:18:23.506290Z",
     "iopub.status.busy": "2025-05-22T20:18:23.505653Z",
     "iopub.status.idle": "2025-05-22T20:18:23.791263Z",
     "shell.execute_reply": "2025-05-22T20:18:23.790470Z",
     "shell.execute_reply.started": "2025-05-22T20:18:23.506249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"best_global_step\": 3130,\n",
      "  \"best_metric\": 0.992173814755752,\n",
      "  \"best_model_checkpoint\": \"./results/tinybert_welfake_run_42/checkpoint-3130\",\n",
      "  \"epoch\": 4.994249201277955,\n",
      "  \"eval_steps\": 1565,\n",
      "  \"global_step\": 3910,\n",
      "  \"is_hyper_param_search\": false,\n",
      "  \"is_local_process_zero\": true,\n",
      "  \"is_world_process_zero\": true,\n",
      "  \"log_history\": [\n",
      "    {\n",
      "      \"epoch\": 0.06389776357827476,\n",
      "      \"grad_norm\": 16677.654296875,\n",
      "      \"learning_rate\": 3.1309904153354634e-06,\n",
      "      \"loss\": 0.6925,\n",
      "      \"step\": 50\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.12779552715654952,\n",
      "      \"grad_norm\": 60503.01953125,\n",
      "      \"learning_rate\": 6.325878594249201e-06,\n",
      "      \"loss\": 0.6809,\n",
      "      \"step\": 100\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.19169329073482427,\n",
      "      \"grad_norm\": 370875.53125,\n",
      "      \"learning_rate\": 9.52076677316294e-06,\n",
      "      \"loss\": 0.6105,\n",
      "      \"step\": 150\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.25559105431309903,\n",
      "      \"grad_norm\": 281786.0625,\n",
      "      \"learning_rate\": 1.2715654952076678e-05,\n",
      "      \"loss\": 0.4738,\n",
      "      \"step\": 200\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.3194888178913738,\n",
      "      \"grad_norm\": 1121344.75,\n",
      "      \"learning_rate\": 1.5910543130990417e-05,\n",
      "      \"loss\": 0.3535,\n",
      "      \"step\": 250\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.38338658146964855,\n",
      "      \"grad_norm\": 294146.1875,\n",
      "      \"learning_rate\": 1.9105431309904154e-05,\n",
      "      \"loss\": 0.2926,\n",
      "      \"step\": 300\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.4472843450479233,\n",
      "      \"grad_norm\": 151610.40625,\n",
      "      \"learning_rate\": 2.2300319488817892e-05,\n",
      "      \"loss\": 0.2528,\n",
      "      \"step\": 350\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.5111821086261981,\n",
      "      \"grad_norm\": 1360000.875,\n",
      "      \"learning_rate\": 2.549520766773163e-05,\n",
      "      \"loss\": 0.2082,\n",
      "      \"step\": 400\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.5750798722044729,\n",
      "      \"grad_norm\": 513707.40625,\n",
      "      \"learning_rate\": 2.869009584664537e-05,\n",
      "      \"loss\": 0.178,\n",
      "      \"step\": 450\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.6389776357827476,\n",
      "      \"grad_norm\": 527499.625,\n",
      "      \"learning_rate\": 3.1884984025559104e-05,\n",
      "      \"loss\": 0.1348,\n",
      "      \"step\": 500\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.7028753993610224,\n",
      "      \"grad_norm\": 349590.53125,\n",
      "      \"learning_rate\": 3.5079872204472845e-05,\n",
      "      \"loss\": 0.1205,\n",
      "      \"step\": 550\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.7667731629392971,\n",
      "      \"grad_norm\": 1323155.625,\n",
      "      \"learning_rate\": 3.827476038338658e-05,\n",
      "      \"loss\": 0.1097,\n",
      "      \"step\": 600\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.8306709265175719,\n",
      "      \"grad_norm\": 513134.71875,\n",
      "      \"learning_rate\": 4.146964856230032e-05,\n",
      "      \"loss\": 0.1074,\n",
      "      \"step\": 650\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.8945686900958466,\n",
      "      \"grad_norm\": 53906.15234375,\n",
      "      \"learning_rate\": 4.466453674121406e-05,\n",
      "      \"loss\": 0.0981,\n",
      "      \"step\": 700\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 0.9584664536741214,\n",
      "      \"grad_norm\": 172271.640625,\n",
      "      \"learning_rate\": 4.78594249201278e-05,\n",
      "      \"loss\": 0.0716,\n",
      "      \"step\": 750\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.0217252396166134,\n",
      "      \"grad_norm\": 1870496.75,\n",
      "      \"learning_rate\": 5.105431309904154e-05,\n",
      "      \"loss\": 0.0734,\n",
      "      \"step\": 800\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.0856230031948881,\n",
      "      \"grad_norm\": 223675.890625,\n",
      "      \"learning_rate\": 5.4249201277955276e-05,\n",
      "      \"loss\": 0.0953,\n",
      "      \"step\": 850\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.149520766773163,\n",
      "      \"grad_norm\": 149833.9375,\n",
      "      \"learning_rate\": 5.744408945686901e-05,\n",
      "      \"loss\": 0.0718,\n",
      "      \"step\": 900\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.2134185303514378,\n",
      "      \"grad_norm\": 65359.57421875,\n",
      "      \"learning_rate\": 6.0638977635782744e-05,\n",
      "      \"loss\": 0.0698,\n",
      "      \"step\": 950\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.2773162939297125,\n",
      "      \"grad_norm\": 5155.4892578125,\n",
      "      \"learning_rate\": 6.383386581469649e-05,\n",
      "      \"loss\": 0.0664,\n",
      "      \"step\": 1000\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.3412140575079872,\n",
      "      \"grad_norm\": 107648.78125,\n",
      "      \"learning_rate\": 6.702875399361023e-05,\n",
      "      \"loss\": 0.0847,\n",
      "      \"step\": 1050\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.4051118210862619,\n",
      "      \"grad_norm\": 20307.06640625,\n",
      "      \"learning_rate\": 7.022364217252396e-05,\n",
      "      \"loss\": 0.0803,\n",
      "      \"step\": 1100\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.4690095846645368,\n",
      "      \"grad_norm\": 241344.015625,\n",
      "      \"learning_rate\": 7.341853035143771e-05,\n",
      "      \"loss\": 0.0788,\n",
      "      \"step\": 1150\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.5329073482428115,\n",
      "      \"grad_norm\": 783269.0,\n",
      "      \"learning_rate\": 7.661341853035144e-05,\n",
      "      \"loss\": 0.0718,\n",
      "      \"step\": 1200\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.5968051118210864,\n",
      "      \"grad_norm\": 6021.5869140625,\n",
      "      \"learning_rate\": 7.980830670926518e-05,\n",
      "      \"loss\": 0.1033,\n",
      "      \"step\": 1250\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.6607028753993611,\n",
      "      \"grad_norm\": 147629.984375,\n",
      "      \"learning_rate\": 8.300319488817891e-05,\n",
      "      \"loss\": 0.0853,\n",
      "      \"step\": 1300\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.7246006389776358,\n",
      "      \"grad_norm\": 24311.056640625,\n",
      "      \"learning_rate\": 8.619808306709266e-05,\n",
      "      \"loss\": 0.0761,\n",
      "      \"step\": 1350\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.7884984025559105,\n",
      "      \"grad_norm\": 1358280.625,\n",
      "      \"learning_rate\": 8.939297124600639e-05,\n",
      "      \"loss\": 0.0886,\n",
      "      \"step\": 1400\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.8523961661341852,\n",
      "      \"grad_norm\": 12.14911937713623,\n",
      "      \"learning_rate\": 9.258785942492013e-05,\n",
      "      \"loss\": 0.1635,\n",
      "      \"step\": 1450\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.91629392971246,\n",
      "      \"grad_norm\": 1175336.625,\n",
      "      \"learning_rate\": 9.578274760383387e-05,\n",
      "      \"loss\": 0.1401,\n",
      "      \"step\": 1500\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.9801916932907349,\n",
      "      \"grad_norm\": 3.110119342803955,\n",
      "      \"learning_rate\": 9.897763578274761e-05,\n",
      "      \"loss\": 0.1288,\n",
      "      \"step\": 1550\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 1.999361022364217,\n",
      "      \"eval_accuracy\": 0.9872356284356657,\n",
      "      \"eval_f1\": 0.9872365452565557,\n",
      "      \"eval_loss\": 0.1313144862651825,\n",
      "      \"eval_precision\": 0.9872753293823872,\n",
      "      \"eval_recall\": 0.9872356284356657,\n",
      "      \"eval_runtime\": 17.4495,\n",
      "      \"eval_samples_per_second\": 615.089,\n",
      "      \"eval_steps_per_second\": 4.814,\n",
      "      \"step\": 1565\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.043450479233227,\n",
      "      \"grad_norm\": 1.235701560974121,\n",
      "      \"learning_rate\": 9.999856123390261e-05,\n",
      "      \"loss\": 0.0988,\n",
      "      \"step\": 1600\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.1073482428115016,\n",
      "      \"grad_norm\": 0.32930344343185425,\n",
      "      \"learning_rate\": 9.999121826549094e-05,\n",
      "      \"loss\": 0.1132,\n",
      "      \"step\": 1650\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.1712460063897763,\n",
      "      \"grad_norm\": 393513.4375,\n",
      "      \"learning_rate\": 9.997765338799969e-05,\n",
      "      \"loss\": 0.1538,\n",
      "      \"step\": 1700\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.235143769968051,\n",
      "      \"grad_norm\": 0.4512195587158203,\n",
      "      \"learning_rate\": 9.995786828971406e-05,\n",
      "      \"loss\": 0.1754,\n",
      "      \"step\": 1750\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.299041533546326,\n",
      "      \"grad_norm\": 0.19526325166225433,\n",
      "      \"learning_rate\": 9.99318654330882e-05,\n",
      "      \"loss\": 0.1039,\n",
      "      \"step\": 1800\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.362939297124601,\n",
      "      \"grad_norm\": 2734702.25,\n",
      "      \"learning_rate\": 9.989964805443873e-05,\n",
      "      \"loss\": 0.1425,\n",
      "      \"step\": 1850\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.4268370607028755,\n",
      "      \"grad_norm\": 1.3457058668136597,\n",
      "      \"learning_rate\": 9.98612201635419e-05,\n",
      "      \"loss\": 0.0817,\n",
      "      \"step\": 1900\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.4907348242811502,\n",
      "      \"grad_norm\": 227640.515625,\n",
      "      \"learning_rate\": 9.981658654313457e-05,\n",
      "      \"loss\": 0.1482,\n",
      "      \"step\": 1950\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.554632587859425,\n",
      "      \"grad_norm\": 0.6140879988670349,\n",
      "      \"learning_rate\": 9.976575274831902e-05,\n",
      "      \"loss\": 0.0618,\n",
      "      \"step\": 2000\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.6185303514376996,\n",
      "      \"grad_norm\": 1212602.5,\n",
      "      \"learning_rate\": 9.970872510587141e-05,\n",
      "      \"loss\": 0.1789,\n",
      "      \"step\": 2050\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.6824281150159743,\n",
      "      \"grad_norm\": 1113545.375,\n",
      "      \"learning_rate\": 9.964551071345448e-05,\n",
      "      \"loss\": 0.1076,\n",
      "      \"step\": 2100\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.746325878594249,\n",
      "      \"grad_norm\": 278.75189208984375,\n",
      "      \"learning_rate\": 9.95761174387341e-05,\n",
      "      \"loss\": 0.1498,\n",
      "      \"step\": 2150\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.8102236421725237,\n",
      "      \"grad_norm\": 4527725.5,\n",
      "      \"learning_rate\": 9.950055391840007e-05,\n",
      "      \"loss\": 0.1215,\n",
      "      \"step\": 2200\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.874121405750799,\n",
      "      \"grad_norm\": 2923203.0,\n",
      "      \"learning_rate\": 9.941882955709128e-05,\n",
      "      \"loss\": 0.105,\n",
      "      \"step\": 2250\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 2.9380191693290736,\n",
      "      \"grad_norm\": 1551833.375,\n",
      "      \"learning_rate\": 9.933095452622506e-05,\n",
      "      \"loss\": 0.1362,\n",
      "      \"step\": 2300\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.0012779552715654,\n",
      "      \"grad_norm\": 1.2495949268341064,\n",
      "      \"learning_rate\": 9.923693976273139e-05,\n",
      "      \"loss\": 0.102,\n",
      "      \"step\": 2350\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.06517571884984,\n",
      "      \"grad_norm\": 0.09414571523666382,\n",
      "      \"learning_rate\": 9.913679696769156e-05,\n",
      "      \"loss\": 0.069,\n",
      "      \"step\": 2400\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.1290734824281152,\n",
      "      \"grad_norm\": 0.10451719164848328,\n",
      "      \"learning_rate\": 9.9030538604882e-05,\n",
      "      \"loss\": 0.0706,\n",
      "      \"step\": 2450\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.19297124600639,\n",
      "      \"grad_norm\": 0.11567217111587524,\n",
      "      \"learning_rate\": 9.891817789922289e-05,\n",
      "      \"loss\": 0.0825,\n",
      "      \"step\": 2500\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.2568690095846646,\n",
      "      \"grad_norm\": 127.13768768310547,\n",
      "      \"learning_rate\": 9.879972883513226e-05,\n",
      "      \"loss\": 0.0901,\n",
      "      \"step\": 2550\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.3207667731629393,\n",
      "      \"grad_norm\": 33266.9765625,\n",
      "      \"learning_rate\": 9.867520615478554e-05,\n",
      "      \"loss\": 0.1566,\n",
      "      \"step\": 2600\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.384664536741214,\n",
      "      \"grad_norm\": 608473.5,\n",
      "      \"learning_rate\": 9.854462535628059e-05,\n",
      "      \"loss\": 0.063,\n",
      "      \"step\": 2650\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.4485623003194887,\n",
      "      \"grad_norm\": 2465698.5,\n",
      "      \"learning_rate\": 9.840800269170898e-05,\n",
      "      \"loss\": 0.0757,\n",
      "      \"step\": 2700\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.5124600638977634,\n",
      "      \"grad_norm\": 13.255252838134766,\n",
      "      \"learning_rate\": 9.826535516513317e-05,\n",
      "      \"loss\": 0.0914,\n",
      "      \"step\": 2750\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.5763578274760386,\n",
      "      \"grad_norm\": 0.0952417403459549,\n",
      "      \"learning_rate\": 9.811670053047015e-05,\n",
      "      \"loss\": 0.0592,\n",
      "      \"step\": 2800\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.640255591054313,\n",
      "      \"grad_norm\": 197183.453125,\n",
      "      \"learning_rate\": 9.796205728928189e-05,\n",
      "      \"loss\": 0.0719,\n",
      "      \"step\": 2850\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.704153354632588,\n",
      "      \"grad_norm\": 0.07175199687480927,\n",
      "      \"learning_rate\": 9.780144468847252e-05,\n",
      "      \"loss\": 0.0599,\n",
      "      \"step\": 2900\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.7680511182108627,\n",
      "      \"grad_norm\": 8009804.5,\n",
      "      \"learning_rate\": 9.763488271789294e-05,\n",
      "      \"loss\": 0.1033,\n",
      "      \"step\": 2950\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.8319488817891374,\n",
      "      \"grad_norm\": 0.06122162193059921,\n",
      "      \"learning_rate\": 9.746239210785286e-05,\n",
      "      \"loss\": 0.0679,\n",
      "      \"step\": 3000\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.895846645367412,\n",
      "      \"grad_norm\": 2612094.0,\n",
      "      \"learning_rate\": 9.72839943265407e-05,\n",
      "      \"loss\": 0.0744,\n",
      "      \"step\": 3050\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.959744408945687,\n",
      "      \"grad_norm\": 461147.84375,\n",
      "      \"learning_rate\": 9.709971157735162e-05,\n",
      "      \"loss\": 0.0782,\n",
      "      \"step\": 3100\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 3.9980830670926517,\n",
      "      \"eval_accuracy\": 0.9921736699897512,\n",
      "      \"eval_f1\": 0.992173814755752,\n",
      "      \"eval_loss\": 0.10568227618932724,\n",
      "      \"eval_precision\": 0.9921756826919884,\n",
      "      \"eval_recall\": 0.9921736699897512,\n",
      "      \"eval_runtime\": 17.4695,\n",
      "      \"eval_samples_per_second\": 614.385,\n",
      "      \"eval_steps_per_second\": 4.808,\n",
      "      \"step\": 3130\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.023003194888179,\n",
      "      \"grad_norm\": 2255843.25,\n",
      "      \"learning_rate\": 9.690956679612421e-05,\n",
      "      \"loss\": 0.0848,\n",
      "      \"step\": 3150\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.086900958466454,\n",
      "      \"grad_norm\": 0.0281254630535841,\n",
      "      \"learning_rate\": 9.671358364828571e-05,\n",
      "      \"loss\": 0.0409,\n",
      "      \"step\": 3200\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.150798722044728,\n",
      "      \"grad_norm\": 0.7044761776924133,\n",
      "      \"learning_rate\": 9.651178652590678e-05,\n",
      "      \"loss\": 0.0698,\n",
      "      \"step\": 3250\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.214696485623003,\n",
      "      \"grad_norm\": 0.044164542108774185,\n",
      "      \"learning_rate\": 9.630420054466554e-05,\n",
      "      \"loss\": 0.0474,\n",
      "      \"step\": 3300\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.278594249201278,\n",
      "      \"grad_norm\": 0.06274691224098206,\n",
      "      \"learning_rate\": 9.609085154072178e-05,\n",
      "      \"loss\": 0.0556,\n",
      "      \"step\": 3350\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.3424920127795525,\n",
      "      \"grad_norm\": 202.1715850830078,\n",
      "      \"learning_rate\": 9.587176606750124e-05,\n",
      "      \"loss\": 0.0647,\n",
      "      \"step\": 3400\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.406389776357828,\n",
      "      \"grad_norm\": 0.01644953526556492,\n",
      "      \"learning_rate\": 9.564697139239099e-05,\n",
      "      \"loss\": 0.0581,\n",
      "      \"step\": 3450\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.470287539936102,\n",
      "      \"grad_norm\": 1.1411664485931396,\n",
      "      \"learning_rate\": 9.541649549334549e-05,\n",
      "      \"loss\": 0.0351,\n",
      "      \"step\": 3500\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.534185303514377,\n",
      "      \"grad_norm\": 0.1264401227235794,\n",
      "      \"learning_rate\": 9.518036705540458e-05,\n",
      "      \"loss\": 0.0681,\n",
      "      \"step\": 3550\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.598083067092652,\n",
      "      \"grad_norm\": 0.04241360351443291,\n",
      "      \"learning_rate\": 9.493861546712341e-05,\n",
      "      \"loss\": 0.0566,\n",
      "      \"step\": 3600\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.6619808306709265,\n",
      "      \"grad_norm\": 0.1698080599308014,\n",
      "      \"learning_rate\": 9.469127081691458e-05,\n",
      "      \"loss\": 0.0437,\n",
      "      \"step\": 3650\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.725878594249202,\n",
      "      \"grad_norm\": 0.044430121779441833,\n",
      "      \"learning_rate\": 9.443836388930338e-05,\n",
      "      \"loss\": 0.0391,\n",
      "      \"step\": 3700\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.789776357827476,\n",
      "      \"grad_norm\": 0.18907137215137482,\n",
      "      \"learning_rate\": 9.417992616109644e-05,\n",
      "      \"loss\": 0.0974,\n",
      "      \"step\": 3750\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.853674121405751,\n",
      "      \"grad_norm\": 0.18376335501670837,\n",
      "      \"learning_rate\": 9.391598979746403e-05,\n",
      "      \"loss\": 0.0612,\n",
      "      \"step\": 3800\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.917571884984025,\n",
      "      \"grad_norm\": 2373539.25,\n",
      "      \"learning_rate\": 9.364658764793681e-05,\n",
      "      \"loss\": 0.0865,\n",
      "      \"step\": 3850\n",
      "    },\n",
      "    {\n",
      "      \"epoch\": 4.9814696485623005,\n",
      "      \"grad_norm\": 0.07919292896986008,\n",
      "      \"learning_rate\": 9.33717532423174e-05,\n",
      "      \"loss\": 0.0373,\n",
      "      \"step\": 3900\n",
      "    }\n",
      "  ],\n",
      "  \"logging_steps\": 50,\n",
      "  \"max_steps\": 3910,\n",
      "  \"num_input_tokens_seen\": 0,\n",
      "  \"num_train_epochs\": 5,\n",
      "  \"save_steps\": 3130,\n",
      "  \"stateful_callbacks\": {\n",
      "    \"EarlyStoppingCallback\": {\n",
      "      \"args\": {\n",
      "        \"early_stopping_patience\": 5,\n",
      "        \"early_stopping_threshold\": 0.001\n",
      "      },\n",
      "      \"attributes\": {\n",
      "        \"early_stopping_patience_counter\": 0\n",
      "      }\n",
      "    },\n",
      "    \"TrainerControl\": {\n",
      "      \"args\": {\n",
      "        \"should_epoch_stop\": false,\n",
      "        \"should_evaluate\": false,\n",
      "        \"should_log\": false,\n",
      "        \"should_save\": true,\n",
      "        \"should_training_stop\": true\n",
      "      },\n",
      "      \"attributes\": {}\n",
      "    }\n",
      "  },\n",
      "  \"total_flos\": 3585953531682816.0,\n",
      "  \"train_batch_size\": 32,\n",
      "  \"trial_name\": null,\n",
      "  \"trial_params\": null\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Example path\n",
    "!cat /kaggle/working/results/tinybert_welfake_run_42/checkpoint-3910/trainer_state.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3eba8-8414-4e8b-ac3e-c281ddf14274",
   "metadata": {},
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "348a1239-c252-4d7b-bcd5-dc527f4b765b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T20:22:07.274028Z",
     "iopub.status.busy": "2025-05-22T20:22:07.273702Z",
     "iopub.status.idle": "2025-05-22T20:22:07.467894Z",
     "shell.execute_reply": "2025-05-22T20:22:07.467205Z",
     "shell.execute_reply.started": "2025-05-22T20:22:07.274007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tinybert_welfake_best/tokenizer_config.json',\n",
       " './tinybert_welfake_best/special_tokens_map.json',\n",
       " './tinybert_welfake_best/vocab.txt',\n",
       " './tinybert_welfake_best/added_tokens.json',\n",
       " './tinybert_welfake_best/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best checkpoint (step 3130)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/results/tinybert_welfake_run_42/checkpoint-3130\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/results/tinybert_welfake_run_42/checkpoint-3130\")\n",
    "\n",
    "# Save for later use\n",
    "model.save_pretrained(\"./tinybert_welfake_best\")\n",
    "tokenizer.save_pretrained(\"./tinybert_welfake_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8c66c",
   "metadata": {},
   "source": [
    "## 16. Conclusion and Key Improvements\n",
    "\n",
    "### What We've Achieved\n",
    "\n",
    "Through this enhanced training approach, we've addressed the major limitations of the original training methodology:\n",
    "\n",
    "1. **Reliability Through Repetition**: By running multiple training sessions with different random seeds, we now have confidence intervals for our performance metrics. This tells us not just that TinyBERT achieves, say, 99.3% accuracy, but that we can expect it to achieve 99.3% ± 0.2% across different training runs.\n",
    "\n",
    "2. **Optimized Hyperparameters**: We've tailored the learning rate (1e-4), warmup strategy, and optimizer settings specifically for TinyBERT's architecture, taking advantage of its distilled nature.\n",
    "\n",
    "3. **Patient Training**: With early stopping patience increased from 2 to 5 and evaluation every half epoch, we allow the model to work through temporary plateaus and find better optima.\n",
    "\n",
    "4. **Comprehensive Evaluation**: The option for k-fold cross-validation ensures every sample is used for both training and testing, giving us the most complete picture of model performance.\n",
    "\n",
    "These improvements transform our evaluation from a single snapshot to a comprehensive assessment of TinyBERT's capabilities for fake news detection. The confidence intervals and consistency measures we now have are essential for making informed decisions about real-world deployment."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7453450,
     "sourceId": 11861402,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
