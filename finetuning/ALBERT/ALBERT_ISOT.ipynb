{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9e04c2",
   "metadata": {},
   "source": [
    "# Fine-tuning ALBERT for Fake News Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook documents the process of fine-tuning an ALBERT model for fake news detection using the ISOT dataset. Building on our previous exploratory data analysis and feature engineering work, we now leverage another lightweight transformer model to capture complex linguistic patterns that differentiate between real and fake news.\n",
    "\n",
    "ALBERT (A Lite BERT) was selected for our comparative evaluation because it represents a different approach to model compression than TinyBERT or DistilBERT. Instead of using knowledge distillation or reducing the model depth, ALBERT achieves efficiency through parameter sharing across layers and factorized embedding parameterization. This allows ALBERT to maintain strong performance while dramatically reducing the parameter count. The ALBERT-base model has approximately 12M parameters, about 80% fewer than BERT-base (110M), making it particularly suitable for resource-constrained environments.\n",
    "\n",
    "## Setup and Environment Preparation\n",
    "\n",
    "### Library Installation and Imports\n",
    "\n",
    "We begin by installing the necessary libraries for our fine-tuning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1560b292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:32:06.577292Z",
     "iopub.status.busy": "2025-05-18T06:32:06.576949Z",
     "iopub.status.idle": "2025-05-18T06:33:41.539732Z",
     "shell.execute_reply": "2025-05-18T06:33:41.538778Z",
     "shell.execute_reply.started": "2025-05-18T06:32:06.577268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch evaluate scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4705060",
   "metadata": {},
   "source": [
    "Next, we import the specific modules needed for our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6418302e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:33:41.542164Z",
     "iopub.status.busy": "2025-05-18T06:33:41.541507Z",
     "iopub.status.idle": "2025-05-18T06:34:27.424212Z",
     "shell.execute_reply": "2025-05-18T06:34:27.423570Z",
     "shell.execute_reply.started": "2025-05-18T06:33:41.542133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 06:34:05.703764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747550046.176443      67 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747550046.306790      67 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import Dataset as HFDataset\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e50ba0",
   "metadata": {},
   "source": [
    "### Setting Up Reproducibility\n",
    "\n",
    "To ensure our experiments are reproducible, we set random seeds for all libraries that use randomization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd426de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:27.425400Z",
     "iopub.status.busy": "2025-05-18T06:34:27.424923Z",
     "iopub.status.idle": "2025-05-18T06:34:27.438693Z",
     "shell.execute_reply": "2025-05-18T06:34:27.437872Z",
     "shell.execute_reply.started": "2025-05-18T06:34:27.425380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06872c",
   "metadata": {},
   "source": [
    "Setting a consistent random seed is critical for several reasons:\n",
    "1. It ensures training results can be replicated exactly\n",
    "2. It allows for fair comparison between different models \n",
    "3. It simplifies debugging by eliminating one source of variability\n",
    "4. It helps in identifying genuine improvements versus random fluctuations\n",
    "\n",
    "### Hardware Configuration\n",
    "\n",
    "We check for GPU availability to accelerate training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fb8bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:27.441264Z",
     "iopub.status.busy": "2025-05-18T06:34:27.441048Z",
     "iopub.status.idle": "2025-05-18T06:34:27.499199Z",
     "shell.execute_reply": "2025-05-18T06:34:27.498546Z",
     "shell.execute_reply.started": "2025-05-18T06:34:27.441249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee960d",
   "metadata": {},
   "source": [
    "ALBERT, while more efficient than BERT, still benefits significantly from GPU acceleration during training. Fine-tuning on CPU is possible but would be considerably slower.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Loading the Dataset\n",
    "\n",
    "We load the preprocessed ISOT dataset that was prepared in our earlier data analysis notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715072cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:27.500594Z",
     "iopub.status.busy": "2025-05-18T06:34:27.500015Z",
     "iopub.status.idle": "2025-05-18T06:34:33.063619Z",
     "shell.execute_reply": "2025-05-18T06:34:33.062809Z",
     "shell.execute_reply.started": "2025-05-18T06:34:27.500566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (62857, 3)\n",
      "Validation set: (13469, 3)\n",
      "Test set: (13470, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed datasets\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/isot-fake-news-robust/train_fake_news_robust.csv')\n",
    "    val_df = pd.read_csv('/kaggle/input/isot-fake-news-robust/val_fake_news_robust.csv') \n",
    "    test_df = pd.read_csv('/kaggle/input/isot-fake-news-robust/test_fake_news_robust.csv')\n",
    "    \n",
    "    print(f\"Training set: {train_df.shape}\")\n",
    "    print(f\"Validation set: {val_df.shape}\")\n",
    "    print(f\"Test set: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Preprocessed files not found. Please run the data preprocessing from Part 2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ed297",
   "metadata": {},
   "source": [
    "The dataset has already been split into training, validation, and test sets with a ratio of 70:15:15. Using this standardized split ensures consistent evaluation across all model comparisons in our study.\n",
    "\n",
    "### Examining the Data\n",
    "\n",
    "We examine the data structure to ensure it matches our expectations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302cda57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:33.064695Z",
     "iopub.status.busy": "2025-05-18T06:34:33.064451Z",
     "iopub.status.idle": "2025-05-18T06:34:33.090088Z",
     "shell.execute_reply": "2025-05-18T06:34:33.089438Z",
     "shell.execute_reply.started": "2025-05-18T06:34:33.064677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>enhanced_cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DESPERATE TO STOP THE FLOW OF MUSLIM REFUGEES ...</td>\n",
       "      <td>The liberals find this plan to be disgusting u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. hands over 1,100 pages of Benghazi record...</td>\n",
       "      <td>The U.S. State Department on Friday handed ove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish minister says EU turning negotiations ...</td>\n",
       "      <td>Turkey said on Friday the European Union was m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  DESPERATE TO STOP THE FLOW OF MUSLIM REFUGEES ...   \n",
       "1  U.S. hands over 1,100 pages of Benghazi record...   \n",
       "2  Turkish minister says EU turning negotiations ...   \n",
       "\n",
       "                               enhanced_cleaned_text  label  \n",
       "0  The liberals find this plan to be disgusting u...      0  \n",
       "1  The U.S. State Department on Friday handed ove...      1  \n",
       "2  Turkey said on Friday the European Union was m...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample of training data:\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0b530",
   "metadata": {},
   "source": [
    "The dataset contains three key columns:\n",
    "- `title`: The headline of the news article\n",
    "- `enhanced_cleaned_text`: The preprocessed body text of the article\n",
    "- `label`: Binary classification (0 for fake news, 1 for real news)\n",
    "\n",
    "### Converting to HuggingFace Dataset Format\n",
    "\n",
    "We convert our pandas DataFrames to the HuggingFace Dataset format, which is optimized for working with transformer models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2a9db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:33.091190Z",
     "iopub.status.busy": "2025-05-18T06:34:33.090936Z",
     "iopub.status.idle": "2025-05-18T06:34:33.122900Z",
     "shell.execute_reply": "2025-05-18T06:34:33.122130Z",
     "shell.execute_reply.started": "2025-05-18T06:34:33.091163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert pandas DataFrames to HuggingFace Datasets\n",
    "def convert_to_hf_dataset(df):\n",
    "    # For ALBERT, we'll combine title and text for better context\n",
    "    df['text'] = df['title'] + \" \" + df['enhanced_cleaned_text']\n",
    "    \n",
    "    # Convert to HuggingFace Dataset format\n",
    "    dataset = HFDataset.from_pandas(df[['text', 'label']])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1798be7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:33.124457Z",
     "iopub.status.busy": "2025-05-18T06:34:33.123781Z",
     "iopub.status.idle": "2025-05-18T06:34:35.681425Z",
     "shell.execute_reply": "2025-05-18T06:34:35.680769Z",
     "shell.execute_reply.started": "2025-05-18T06:34:33.124436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert our datasets\n",
    "train_dataset = convert_to_hf_dataset(train_df)\n",
    "val_dataset = convert_to_hf_dataset(val_df)\n",
    "test_dataset = convert_to_hf_dataset(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e18e1",
   "metadata": {},
   "source": [
    "We combine the title and body text for each article because:\n",
    "1. Article titles often contain strong signals for fake news detection\n",
    "2. The full context helps the model identify inconsistencies between headline and content\n",
    "3. ALBERT, like other transformer models, processes text as a sequence and can learn relationships between title and content \n",
    "4. This matches our preprocessing approach across all models for fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b0a75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:35.682474Z",
     "iopub.status.busy": "2025-05-18T06:34:35.682220Z",
     "iopub.status.idle": "2025-05-18T06:34:40.582382Z",
     "shell.execute_reply": "2025-05-18T06:34:40.581556Z",
     "shell.execute_reply.started": "2025-05-18T06:34:35.682455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example in train_dataset: {'text': 'DESPERATE TO STOP THE FLOW OF MUSLIM REFUGEES INTO SWEDEN, Swedish Citizens Devise A Controversial Scheme The liberals find this plan to be disgusting until their neighborhoods become the next victim of violent muslim immigrant gangs of course Anti-immigration campaigners in Gullberg in southern Sweden are plotting to build a pig farm next to an asylum centre in a last-ditch effort to deter would-be Muslim immigrants, who might find the animals offensive.More illegal immigrants on the run in Sweden (03 May 15) Swedish Syrian warms hearts over phone return (08 Apr 15) It was a long journey and some of my friends died (30 Mar 15)Plans for a new immigration centre in Gullberg have already been strongly opposed by local residents and on Wednesday it was reported that a group of campaigners had sent a letter to the Swedish Migration Board (Migrationsverket) pledging to breed pigs nearby in order to deter Muslims from seeking asylum in the town.The note, signed by what described itself as the interest group for Gullberg s survival said that it was trying to create a probably impossible situation for some religious people, especially Muslims , .Local politician Henry Sandahl from Sweden s Countryside Party (Markbygdspartiet) told the broadcaster that he agreed with the sentiment of the letter. You know that Muslims are not friends with pigs, he said.But Swedish religious experts have been quick to criticize the campaigners. This is nonsense and shows just how very little they know about Islam, said ke Sander, Professor of Psychology at the University of Gothenburg. It is one thing when Muslims try to stay away from pork, alcohol or gambling but there is nothing [in the Koran] that says you cannot be near pigs. This is a last-ditch effort when they [the campaigners] have no arguments left, he told the TT news agency.Others turned to social media to voice their disgust at the campaign.Carl G ransson, a lawyer and former Moderate party politician suggested on Twitter that building a gigantic rubbish dump next to the asylum centre instead, designed to blow smelly winds in the direction of the angry residents. Monstrous and a total fail , wrote Johan Arenius, a political official for the Christian political party party based in rebro in central Sweden.Sweden became the first European country in 2013 to grant automatic residency to Syrian refugees and has since seen asylum requests rise to record levels, which are still expected to reach about 90,000 in 2015.To cope with an increasing flow of refugees, the in March that it was more than tripling the maximum number of residents allowed at asylum centres from 200 to 650. The Local seh/t Refugee Resettlement Watch', 'label': 0}\n",
      "Text type for first example: <class 'str'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3834eba4d4b34f99ade836be9b61759e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62857 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb39acd44b7420eb1929185199ca64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13469 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e3c101b7ff48a8b42fe4c262d9b1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check first few examples in your dataset\n",
    "print(\"First example in train_dataset:\", train_dataset[0])\n",
    "\n",
    "# Debug the content types\n",
    "print(\"Text type for first example:\", type(train_dataset[0]['text']))\n",
    "\n",
    "# Clean the dataset before tokenization\n",
    "def clean_dataset(example):\n",
    "    example['text'] = str(example['text']) if example['text'] is not None else \"\"\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(clean_dataset)\n",
    "val_dataset = val_dataset.map(clean_dataset)\n",
    "test_dataset = test_dataset.map(clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f944d2",
   "metadata": {},
   "source": [
    "This cleaning step ensures that all text entries are properly formatted as strings, preventing potential errors during tokenization. It's a defensive programming practice that handles edge cases like None values or non-string data types.\n",
    "\n",
    "## Model Architecture and Configuration\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "We prepare the tokenizer for ALBERT, which converts text into token IDs that the model can process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f66c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:40.585034Z",
     "iopub.status.busy": "2025-05-18T06:34:40.584839Z",
     "iopub.status.idle": "2025-05-18T06:34:41.542710Z",
     "shell.execute_reply": "2025-05-18T06:34:41.542059Z",
     "shell.execute_reply.started": "2025-05-18T06:34:40.585020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966722d772f4cc98ae71a1b84005145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf79fab5bea14ac2a08b31bd9a2514c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eb973c47fe44df81e1545e9df3336a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cb47d32d6b471b9885e5814f9c62d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Define the tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the texts with truncation and padding\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1e7a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:34:41.543674Z",
     "iopub.status.busy": "2025-05-18T06:34:41.543441Z",
     "iopub.status.idle": "2025-05-18T06:40:22.957757Z",
     "shell.execute_reply": "2025-05-18T06:40:22.956976Z",
     "shell.execute_reply.started": "2025-05-18T06:34:41.543656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b63867b05b4a52bdc300c653bbbccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62857 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb61af7450e46fb8f9ccf1a6ee9c6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13469 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3891155aa73b4953b3e67863883e9997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply tokenization to our datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d795b07",
   "metadata": {},
   "source": [
    "Key tokenization decisions:\n",
    "- We use the `albert-base-v2` tokenizer, which uses SentencePiece tokenization (different from BERT's WordPiece)\n",
    "- `max_length=512` matches ALBERT's maximum sequence length\n",
    "- `padding='max_length'` ensures all sequences have the same length for batch processing\n",
    "- `truncation=True` handles articles that exceed the maximum length\n",
    "- `batched=True` enables efficient parallel processing\n",
    "\n",
    "ALBERT's SentencePiece tokenizer has some advantages over BERT's WordPiece tokenizer:\n",
    "1. It's language-agnostic and works well for multilingual applications\n",
    "2. It handles out-of-vocabulary words more gracefully \n",
    "3. It tends to create more consistent subword units\n",
    "\n",
    "### Model Initialization\n",
    "\n",
    "We initialize the ALBERT model for sequence classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bae8f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:40:22.958996Z",
     "iopub.status.busy": "2025-05-18T06:40:22.958659Z",
     "iopub.status.idle": "2025-05-18T06:40:25.230331Z",
     "shell.execute_reply": "2025-05-18T06:40:25.229501Z",
     "shell.execute_reply.started": "2025-05-18T06:40:22.958968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af76baad7c74281ae0efcf2e0e7a545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertSdpaAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = AlbertForSequenceClassification.from_pretrained(\n",
    "    'albert-base-v2',\n",
    "    num_labels=2,  # Binary classification: fake or real\n",
    "    id2label={0: \"fake\", 1: \"real\"},\n",
    "    label2id={\"fake\": 0, \"real\": 1}\n",
    ")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fb673",
   "metadata": {},
   "source": [
    "We use the pretrained ALBERT model and adapt it for our binary classification task. The pretrained weights provide a strong starting point that captures general language understanding, which we'll fine-tune for our specific task of fake news detection.\n",
    "\n",
    "ALBERT's architecture differs from BERT in three key ways:\n",
    "1. **Factorized embedding parameterization**: Separates the size of the hidden layers from the size of vocabulary embeddings\n",
    "2. **Cross-layer parameter sharing**: All transformer layers share the same parameters, dramatically reducing model size\n",
    "3. **Sentence-order prediction (SOP)**: Replaces BERT's next sentence prediction with a more challenging task \n",
    "\n",
    "These architectural differences make ALBERT particularly efficient in terms of parameter count while maintaining strong performance.\n",
    "\n",
    "## Training Process\n",
    "\n",
    "### Defining Metrics\n",
    "\n",
    "We define a function to compute evaluation metrics during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1874fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:40:25.231440Z",
     "iopub.status.busy": "2025-05-18T06:40:25.231162Z",
     "iopub.status.idle": "2025-05-18T06:40:25.236166Z",
     "shell.execute_reply": "2025-05-18T06:40:25.235384Z",
     "shell.execute_reply.started": "2025-05-18T06:40:25.231414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define metrics computation function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc942f",
   "metadata": {},
   "source": [
    "We track multiple metrics because accuracy alone can be misleading, especially if the dataset is imbalanced:\n",
    "- Accuracy: Overall correctness of predictions\n",
    "- Precision: Proportion of positive identifications that were actually correct\n",
    "- Recall: Proportion of actual positives that were identified correctly\n",
    "- F1 Score: Harmonic mean of precision and recall, providing a balance between the two\n",
    "\n",
    "For fake news detection, both false positives (legitimate news incorrectly flagged as fake) and false negatives (fake news missed by the model) have important consequences, making the F1 score particularly valuable.\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "We set up the training arguments with carefully chosen hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c13c28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:40:25.237125Z",
     "iopub.status.busy": "2025-05-18T06:40:25.236930Z",
     "iopub.status.idle": "2025-05-18T06:40:25.294954Z",
     "shell.execute_reply": "2025-05-18T06:40:25.294118Z",
     "shell.execute_reply.started": "2025-05-18T06:40:25.237110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results/albert',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,  # Smaller than BERT due to memory constraints\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    disable_tqdm=False,          # Ensure progress bar is shown\n",
    "    logging_first_step=True,     # Log the first training step \n",
    "    report_to=\"tensorboard\",     # Enable tensorboard reporting (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec15ef",
   "metadata": {},
   "source": [
    "Key hyperparameter choices and their rationale:\n",
    "- `num_train_epochs=5`: Provides sufficient training iterations while avoiding overfitting\n",
    "- `per_device_train_batch_size=16`: Balances memory constraints with training efficiency; ALBERT is smaller than BERT but larger than TinyBERT\n",
    "- `warmup_steps=500`: Gradually increases the learning rate to stabilize early training\n",
    "- `weight_decay=0.01`: Adds L2 regularization to prevent overfitting\n",
    "- `evaluation_strategy=\"epoch\"`: Evaluates after each epoch to track progress\n",
    "- `metric_for_best_model=\"f1\"`: Uses F1 score as the primary metric for model selection because it balances precision and recall\n",
    "\n",
    "### Training Execution\n",
    "\n",
    "We initialize the Trainer and start the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b5729b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:40:25.296292Z",
     "iopub.status.busy": "2025-05-18T06:40:25.295925Z",
     "iopub.status.idle": "2025-05-18T06:40:25.745140Z",
     "shell.execute_reply": "2025-05-18T06:40:25.744527Z",
     "shell.execute_reply.started": "2025-05-18T06:40:25.296272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c4ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T06:40:25.746074Z",
     "iopub.status.busy": "2025-05-18T06:40:25.745867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3111' max='9825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3111/9825 1:32:30 < 3:19:47, 0.56 it/s, Epoch 1.58/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.999629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89475da-7587-43ed-b496-71745b2a1dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:17:44.351888Z",
     "iopub.status.busy": "2025-05-18T08:17:44.351545Z",
     "iopub.status.idle": "2025-05-18T10:16:18.089523Z",
     "shell.execute_reply": "2025-05-18T10:16:18.088725Z",
     "shell.execute_reply.started": "2025-05-18T08:17:44.351862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5895' max='9825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5895/9825 1:58:31 < 1:58:34, 0.55 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.999332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5895, training_loss=0.029435520411919398, metrics={'train_runtime': 7112.7124, 'train_samples_per_second': 44.186, 'train_steps_per_second': 1.381, 'total_flos': 4510312643266560.0, 'train_loss': 0.029435520411919398, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5be74",
   "metadata": {},
   "source": [
    "We include an early stopping callback with a patience of 2 epochs to prevent overfitting. This means training will stop if the F1 score on the validation set doesn't improve for 2 consecutive epochs. This is especially important for pretrained models, which can quickly overfit to the training data.\n",
    "\n",
    "The Hugging Face Trainer abstracts away many of the training loop details, handling:\n",
    "1. Gradient computation and optimization\n",
    "2. Learning rate scheduling\n",
    "3. Model checkpointing\n",
    "4. Progress tracking\n",
    "5. Resource management\n",
    "\n",
    "This allows us to focus on the model architecture and hyperparameters rather than low-level implementation details.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "We evaluate the model on both validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49aa499e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:18:08.284217Z",
     "iopub.status.busy": "2025-05-18T10:18:08.283399Z",
     "iopub.status.idle": "2025-05-18T10:22:20.840784Z",
     "shell.execute_reply": "2025-05-18T10:22:20.840084Z",
     "shell.execute_reply.started": "2025-05-18T10:18:08.284192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: {'eval_loss': 0.0024346422869712114, 'eval_accuracy': 0.9996287771920707, 'eval_precision': 0.9996288689366757, 'eval_recall': 0.9996287771920707, 'eval_f1': 0.9996287733655616, 'eval_runtime': 252.5449, 'eval_samples_per_second': 53.333, 'eval_steps_per_second': 0.42, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_results = trainer.evaluate(tokenized_val)\n",
    "print(f\"Validation results: {val_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b28a8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:22:24.585922Z",
     "iopub.status.busy": "2025-05-18T10:22:24.585621Z",
     "iopub.status.idle": "2025-05-18T10:26:35.680184Z",
     "shell.execute_reply": "2025-05-18T10:26:35.679378Z",
     "shell.execute_reply.started": "2025-05-18T10:22:24.585902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "Test results: {'eval_loss': 0.0024632636923342943, 'eval_accuracy': 0.9997030438010394, 'eval_precision': 0.9997032123107281, 'eval_recall': 0.9997030438010394, 'eval_f1': 0.9997030397071623, 'eval_runtime': 251.0838, 'eval_samples_per_second': 53.647, 'eval_steps_per_second': 0.422, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(tokenized_test)\n",
    "print(f\"Test results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04274d9",
   "metadata": {},
   "source": [
    "Evaluating on both validation and test sets allows us to:\n",
    "1. Confirm that our model selection based on validation performance generalizes to unseen data\n",
    "2. Detect any potential overfitting to the validation set\n",
    "3. Obtain final performance metrics on a completely held-out dataset\n",
    "\n",
    "### Detailed Performance Analysis\n",
    "\n",
    "We perform a more detailed analysis of the model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a32599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:26:35.681799Z",
     "iopub.status.busy": "2025-05-18T10:26:35.681524Z",
     "iopub.status.idle": "2025-05-18T10:30:46.620563Z",
     "shell.execute_reply": "2025-05-18T10:30:46.620008Z",
     "shell.execute_reply.started": "2025-05-18T10:26:35.681771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "test_predictions = trainer.predict(tokenized_test)\n",
    "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "true_labels = test_predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a787470f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:30:46.622662Z",
     "iopub.status.busy": "2025-05-18T10:30:46.622035Z",
     "iopub.status.idle": "2025-05-18T10:30:47.039428Z",
     "shell.execute_reply": "2025-05-18T10:30:47.038714Z",
     "shell.execute_reply.started": "2025-05-18T10:30:46.622640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fake', 'Real'], \n",
    "            yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for ALBERT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b432baa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:30:47.040610Z",
     "iopub.status.busy": "2025-05-18T10:30:47.040320Z",
     "iopub.status.idle": "2025-05-18T10:30:47.056941Z",
     "shell.execute_reply": "2025-05-18T10:30:47.056115Z",
     "shell.execute_reply.started": "2025-05-18T10:30:47.040584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      1.00      1.00      7045\n",
      "        Real       1.00      1.00      1.00      6425\n",
      "\n",
      "    accuracy                           1.00     13470\n",
      "   macro avg       1.00      1.00      1.00     13470\n",
      "weighted avg       1.00      1.00      1.00     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, \n",
    "                           target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11dfd0c",
   "metadata": {},
   "source": [
    "The confusion matrix and classification report provide deeper insights into:\n",
    "- Where the model makes mistakes (false positives vs. false negatives)\n",
    "- Class-specific performance metrics\n",
    "- Overall precision, recall, and F1 score\n",
    "\n",
    "These detailed performance metrics are crucial for comparing ALBERT with other models in our study.\n",
    "\n",
    "## Model Saving\n",
    "\n",
    "We save the fine-tuned model for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71de155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:30:52.719253Z",
     "iopub.status.busy": "2025-05-18T10:30:52.718969Z",
     "iopub.status.idle": "2025-05-18T10:30:52.833871Z",
     "shell.execute_reply": "2025-05-18T10:30:52.833157Z",
     "shell.execute_reply.started": "2025-05-18T10:30:52.719230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./albert-fake-news-detector\n"
     ]
    }
   ],
   "source": [
    "# This saves both the model and tokenizer configuration\n",
    "model_save_path = \"./albert-fake-news-detector\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029c019",
   "metadata": {},
   "source": [
    "Saving the model and tokenizer together ensures that they can be easily loaded for inference or further fine-tuning without needing to recreate the tokenization process.\n",
    "\n",
    "## Results Analysis\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "This section will analyze the ALBERT model's performance on the fake news detection task, focusing on:\n",
    "1. Overall classification accuracy and F1 score\n",
    "2. Performance on each class (fake vs. real news)\n",
    "3. Types of errors made by the model\n",
    "\n",
    "### Error Analysis\n",
    "\n",
    "We analyze the errors to understand where the model struggles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "045986af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T10:30:59.550708Z",
     "iopub.status.busy": "2025-05-18T10:30:59.549801Z",
     "iopub.status.idle": "2025-05-18T10:30:59.561000Z",
     "shell.execute_reply": "2025-05-18T10:30:59.560146Z",
     "shell.execute_reply.started": "2025-05-18T10:30:59.550675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of misclassified examples:\n",
      "Example 1:\n",
      "Title: Billionaire Branson targeted in $5 million scam 'straight out of le Carre'\n",
      "True label: Real\n",
      "Predicted: Fake\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Title: Billionaire Branson targeted in $5 million scam 'straight out of le Carre'\n",
      "True label: Real\n",
      "Predicted: Fake\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Title: Graphic: Supreme Court roundup\n",
      "True label: Real\n",
      "Predicted: Fake\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find misclassified examples\n",
    "misclassified_indices = np.where(predicted_labels != true_labels)[0]\n",
    "misclassified_examples = test_df.iloc[misclassified_indices]\n",
    "\n",
    "# Display some misclassified examples\n",
    "print(\"Sample of misclassified examples:\")\n",
    "for i, (_, row) in enumerate(misclassified_examples.head(3).iterrows()):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"True label: {'Real' if row['label'] == 1 else 'Fake'}\")\n",
    "    print(f\"Predicted: {'Real' if predicted_labels[misclassified_indices[i]] == 1 else 'Fake'}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30523e3",
   "metadata": {},
   "source": [
    "This analysis helps identify patterns in misclassifications, such as:\n",
    "1. Articles with ambiguous language or satire\n",
    "2. Fake news articles that closely mimic legitimate sources\n",
    "3. Real news with unusual or sensationalist headlines\n",
    "\n",
    "Understanding these patterns can guide future improvements to the model or preprocessing steps.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "ALBERT demonstrates strong performance for fake news detection on the ISOT dataset, achieving comparable accuracy to larger models but with significantly fewer parameters. Its unique parameter-sharing approach allows it to maintain high performance while being more efficient than traditional transformer models.\n",
    "\n",
    "### Comparison with Other Models\n",
    "\n",
    "When compared to other models in our study:\n",
    "1. ALBERT offers a better parameter-efficiency than models like DistilBERT or RoBERTa\n",
    "2. It achieves this through architectural innovations rather than knowledge distillation\n",
    "3. The cross-layer parameter sharing in ALBERT makes it especially memory-efficient\n",
    "\n",
    "### Future Work\n",
    "\n",
    "Potential improvements and future directions include:\n",
    "1. Experimenting with different ALBERT variants (tiny, small, large)\n",
    "2. Exploring domain adaptation techniques for news text\n",
    "3. Testing the model on more diverse and challenging fake news datasets\n",
    "4. Combining ALBERT with external knowledge sources for fact verification\n",
    "\n",
    "This investigation of ALBERT completes our exploration of lightweight transformer architectures for fake news detection, providing a comprehensive comparison of different approaches to model efficiency."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7439402,
     "sourceId": 11843281,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
