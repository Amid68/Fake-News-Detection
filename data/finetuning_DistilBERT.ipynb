{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6dU_D-igHSA"
      },
      "source": [
        "# Fake News Detection using DistilBERT\n",
        "\n",
        "This project implements a lightweight fake news detector using DistilBERT. I'm using a dataset with approximately 45,000 labeled news articles to train a binary classifier that can distinguish between real and fake news.\n",
        "\n",
        "## Objectives\n",
        "- Train a transformer-based model for reliable fake news detection\n",
        "- Evaluate model performance on standard metrics\n",
        "- Measure resource usage (memory and processing time)\n",
        "- Create code for integration with my Django web application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFN4-GaIgHSD"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Installing required packages and importing necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-03T12:12:30.179012Z",
          "start_time": "2025-05-03T12:12:29.099850Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfo683zQgHSD",
        "outputId": "c758ef2f-4cf7-4b7b-e63d-472f905c5141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets scikit-learn pandas numpy matplotlib seaborn psutil tqdm accelerate nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJtCxf0ZgHSE"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-03T12:05:06.745211Z",
          "start_time": "2025-05-03T12:05:06.715128Z"
        },
        "id": "yvWpXAOdGWKz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import psutil\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.cuda.amp import autocast, GradScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-03T12:12:23.152077Z",
          "start_time": "2025-05-03T12:12:23.135006Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFgKovXbGWKz",
        "outputId": "98be6bb8-3bc9-4189-f8ea-67a690e95cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ug5lwjiJGWK0"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d-_IIyIGWK0",
        "outputId": "e27eafd5-7484-4ab3-887a-17b0a539dd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ON3GJNGgHSE"
      },
      "source": [
        "## Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoseaQBPgHSE",
        "outputId": "99137de2-b443-4e4b-9145-cd82a5eac91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake news dataset shape: (23481, 4)\n",
            "Real news dataset shape: (21417, 4)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    fake_news = pd.read_csv(\"/content/Fake.csv\")\n",
        "    real_news = pd.read_csv(\"/content/True.csv\")\n",
        "\n",
        "    print(f\"Fake news dataset shape: {fake_news.shape}\")\n",
        "    print(f\"Real news dataset shape: {real_news.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    raise SystemExit(f\"Critical data missing: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mieNXt9agHSE"
      },
      "outputs": [],
      "source": [
        "# Add labels\n",
        "fake_news['label'] = 1\n",
        "real_news['label'] = 0\n",
        "\n",
        "# Fix: Correct splitting to prevent data leakage\n",
        "full_df = pd.concat([fake_news, real_news]).sample(frac=1, random_state=SEED)\n",
        "train_val_df, test_df = train_test_split(\n",
        "    full_df,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=full_df['label']\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.15,\n",
        "    random_state=SEED,\n",
        "    stratify=train_val_df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wfNrvR_ogHSE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import psutil\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ousU1CpdAtIV"
      },
      "source": [
        "## Dataset Analysis\n",
        "\n",
        "The FakeNewsNet dataset contains:\n",
        "- 23,481 fake news articles\n",
        "- 21,417 real news articles\n",
        "\n",
        "Each article includes the title, full text, subject category, and publication date. I'm preprocessing this data by:\n",
        "1. Combining titles and article text\n",
        "2. Converting to lowercase\n",
        "3. Removing URLs and excessive whitespace\n",
        "4. Splitting into train/validation/test sets with appropriate stratification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "# Preprocess each split individually\n",
        "for df_split in [train_df, val_df, test_df]:\n",
        "    # Apply preprocessing\n",
        "    df_split['processed_text'] = df_split['title'].fillna('').apply(preprocess_text)\n",
        "    # Remove empty texts\n",
        "    empty_mask = df_split['processed_text'].apply(lambda x: len(x.strip()) == 0)\n",
        "    if empty_mask.sum() > 0:\n",
        "        print(f\"Removing {empty_mask.sum()} empty texts\")\n",
        "        df_split.drop(df_split[empty_mask].index, inplace=True)\n",
        "        df_split.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Update the combined df if needed for reference\n",
        "df = pd.concat([train_df, val_df, test_df])\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ],
      "metadata": {
        "id": "oW3-wiLmWin7",
        "outputId": "1bfe9ad3-2a2c-45d0-97fe-707d7e8c8192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 5 empty texts\n",
            "Removing 1 empty texts\n",
            "Removing 3 empty texts\n",
            "Training set size: 30522\n",
            "Validation set size: 5387\n",
            "Test set size: 8977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imc6wzTAgHSF"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWNlV7lYgHSF",
        "outputId": "840088d5-3ffd-442a-924d-04b480bb47f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: title\n",
            "Example: Factbox: Trump on Twitter (April 18) - Obama administration, interview...\n",
            "Average length: 80.11 characters\n",
            "--------------------------------------------------\n",
            "Column: text\n",
            "Example: The following statements were posted to the verified Twitter accounts of U.S. President Donald Trump...\n",
            "Average length: 2469.56 characters\n",
            "--------------------------------------------------\n",
            "Column: subject\n",
            "Example: politicsNews...\n",
            "Average length: 8.80 characters\n",
            "--------------------------------------------------\n",
            "Column: date\n",
            "Example: April 18, 2017 ...\n",
            "Average length: 14.82 characters\n",
            "--------------------------------------------------\n",
            "Column: processed_text\n",
            "Example: factbox: trump on twitter (april 18) - obama administration, interview...\n",
            "Average length: 79.90 characters\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Inspect dataset columns to find title and text columns\n",
        "for col in df.columns:\n",
        "    if col != 'label':\n",
        "        print(f\"Column: {col}\")\n",
        "        print(f\"Example: {df[col].iloc[0][:100]}...\")\n",
        "        print(f\"Average length: {df[col].str.len().mean():.2f} characters\")\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cm-KBb5OgHSF"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V6HMrx6mGWK1"
      },
      "outputs": [],
      "source": [
        "# Use only the title field for training\n",
        "df['processed_text'] = df['title'].fillna('').apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoN9zzwHGWK1",
        "outputId": "1c61d30e-b858-4d16-ab45-98bbb2fca154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty texts after preprocessing: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for empty texts after preprocessing\n",
        "empty_texts = df['processed_text'].apply(lambda x: len(x.strip()) == 0).sum()\n",
        "print(f\"Number of empty texts after preprocessing: {empty_texts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ezmm0QWiGWK1"
      },
      "outputs": [],
      "source": [
        "# Remove empty texts if any\n",
        "if empty_texts > 0:\n",
        "    df = df[df['processed_text'].apply(lambda x: len(x.strip()) > 0)].reset_index(drop=True)\n",
        "    print(f\"Dataset size after removing empty texts: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwCVdc_fGWK1",
        "outputId": "2f6a462e-f555-4f66-e911-7dc75bcc1a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample processed title:\n",
            "factbox: trump on twitter (april 18) - obama administration, interview\n"
          ]
        }
      ],
      "source": [
        "# Display a sample preprocessed text\n",
        "print(\"\\nSample processed title:\")\n",
        "print(df['processed_text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkowR6aFgHSF"
      },
      "source": [
        "## Train/Val/Test Split\n",
        "\n",
        "Dividing the dataset into:\n",
        "- 30,524 training samples (68%)\n",
        "- 5,387 validation samples (12%)\n",
        "- 8,978 test samples (20%)\n",
        "\n",
        "Using stratification to ensure balanced class distribution across splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NKa6c4JfgHSF"
      },
      "outputs": [],
      "source": [
        "# Split data into train, validation, and test sets\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=SEED, stratify=df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t9OLegwwGWK1"
      },
      "outputs": [],
      "source": [
        "# Then split train+val into train and validation\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df, test_size=0.15, random_state=SEED, stratify=train_val_df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIxD5dEXGWK1",
        "outputId": "e788daaa-b121-4eab-cce3-cd6084e71bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 30521\n",
            "Validation set size: 5387\n",
            "Test set size: 8978\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd1gH7ujGWK1",
        "outputId": "d2515e00-df00-4f59-cefa-4a721a4d5e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            "label\n",
            "1    23472\n",
            "0    21414\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Calculate class weights for balanced training\n",
        "# Get class distribution\n",
        "class_counts = df['label'].value_counts()\n",
        "print(\"Class distribution:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9Pf81OPGWK1",
        "outputId": "c3de5efd-5124-464f-d861-f15e65ecedcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "{0: np.float64(1.0480392830162764), 1: np.float64(0.956171679197995)}\n"
          ]
        }
      ],
      "source": [
        "# Calculate class weights\n",
        "classes = np.unique(df['label'])\n",
        "weights = compute_class_weight('balanced', classes=classes, y=train_df['label'])\n",
        "class_weights = {i: weights[i] for i in range(len(weights))}\n",
        "print(\"Class weights:\")\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLtaFwsngHSF"
      },
      "source": [
        "## Create PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XRXCymcMgHSF"
      },
      "outputs": [],
      "source": [
        "# Define model configuration\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LENGTH = 128  # Reduced from 512 as titles are much shorter\n",
        "BATCH_SIZE = 16   # Increased batch size since we're using shorter sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hqSgVGGQgHSG"
      },
      "outputs": [],
      "source": [
        "# Replace the existing FakeNewsDataset class with this modified version\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Remove padding from tokenization\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjGwBSwQGWK2",
        "outputId": "9ac2597f-3f03-4276-a679-252711b651b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymE_fO4LGWK2"
      },
      "source": [
        "### Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cll_HdQQGWK2"
      },
      "outputs": [],
      "source": [
        "train_dataset = FakeNewsDataset(\n",
        "    train_df['processed_text'].tolist(),\n",
        "    train_df['label'].tolist(),\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R_hnJ2EgGWK2"
      },
      "outputs": [],
      "source": [
        "val_dataset = FakeNewsDataset(\n",
        "    val_df['processed_text'].tolist(),\n",
        "    val_df['label'].tolist(),\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2bMugf-RGWK2"
      },
      "outputs": [],
      "source": [
        "test_dataset = FakeNewsDataset(\n",
        "    test_df['processed_text'].tolist(),\n",
        "    test_df['label'].tolist(),\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i_7oJlgTGWK2"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD3TI3dXGWK2"
      },
      "source": [
        "### Create dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XDb7gAbNGWK2"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5NMxBzaLGWK7"
      },
      "outputs": [],
      "source": [
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f_ACHG8qGWK7"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V0YXCjAGWK7"
      },
      "source": [
        "### Custom model with dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Y6qJ47P6gHSG"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertModel\n",
        "\n",
        "class DistilBERTForFakeNews(nn.Module):\n",
        "    def __init__(self, num_labels=2, dropout_rate=0.3):\n",
        "        super(DistilBERTForFakeNews, self).__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout for regularization\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs[0]  # (bs, seq_len, dim)\n",
        "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
        "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
        "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
        "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
        "        logits = self.classifier(pooled_output)  # (bs, num_labels)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiHpzs4ugHSG",
        "outputId": "3e0de92c-ccd1-426c-f455-751997124133"
      },
      "source": [
        "### Manual training loop with class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aXGsGtMiGWK7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    \"\"\"Train model with class weights and early stopping\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    scaler = None\n",
        "    if torch.cuda.is_available():\n",
        "        scaler = torch.amp.GradScaler(init_scale=65536.0, growth_factor=2.0, backoff_factor=0.5)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "    # Set up scheduler\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=lr,\n",
        "        total_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Set up loss function with class weights\n",
        "    class_weights_tensor = torch.tensor([class_weights[0], class_weights[1]], device=device, dtype=torch.float32)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # For early stopping\n",
        "    best_val_f1 = 0\n",
        "    patience = 2\n",
        "    counter = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_preds, train_labels = [], []\n",
        "\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
        "          batch = {k: v.to(device) for k, v in batch.items()}\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward pass with conditional autocast\n",
        "          if scaler:\n",
        "              with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                  outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "              loss = criterion(outputs.float(), batch['labels'])\n",
        "          else:\n",
        "              outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "              loss = criterion(outputs, batch['labels'])\n",
        "\n",
        "          # Backward pass\n",
        "          if scaler:\n",
        "              scaler.scale(loss).backward()\n",
        "              scaler.unscale_(optimizer)\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "              scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "          else:\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "              optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          scheduler.step()\n",
        "\n",
        "          preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "          print(\"Unique predictions:\", np.unique(preds))  # Should see both 0 and 1\n",
        "\n",
        "        train_loss = train_loss / len(train_dataloader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n",
        "            train_labels, train_preds, average='binary'\n",
        "        )\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_preds, val_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "                outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "\n",
        "                loss = criterion(outputs, batch['labels'])\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
        "                labels = batch['labels'].detach().cpu().numpy()\n",
        "\n",
        "                val_preds.extend(preds)\n",
        "                val_labels.extend(labels)\n",
        "\n",
        "        val_loss = val_loss / len(val_dataloader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
        "            val_labels, val_preds, average='binary'\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "        print(\"Sample batch predictions:\", preds[:10])\n",
        "        print(\"Sample batch labels:\", labels[:10])\n",
        "        # Early stopping\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            counter = 0\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_titles = set(train_df['title']).intersection(set(val_df['title']))\n",
        "print(f\"Shared titles between train/val: {len(common_titles)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUxYvk2PP7-U",
        "outputId": "0817fd27-2044-4d29-dbe1-2938c1699e60"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared titles between train/val: 1009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_3nM6UszGWK7"
      },
      "outputs": [],
      "source": [
        "# Initialize our custom model with dropout\n",
        "model = DistilBERTForFakeNews(num_labels=2, dropout_rate=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5cd7cc4f30fb4b1db234204484e891e9",
            "6981aa298cdc4f13a757f61af0054762",
            "f41987886cd145b4b5a864839337fd86",
            "ba5ae5c4849749f9a5e797934226fdb7",
            "5efc3688e8ae4de4a6b14ef12addea65",
            "510ec59810d94a4bac199bfbeeedf000",
            "89721b9ce0144a478e046a795249db55",
            "b0bb76f8b5af4716955adf1a9e3ae08b",
            "a467cdde01c5432096172c4826c89c67",
            "a8411fe68bf9430f93eb1fb85226ea95",
            "04ff2ae881bc4d4390ddff23fa9acdbd",
            "4e125396b17a4a48a83b3e6563f0abab",
            "06190b12d435418cbe5717cb484dccc6",
            "f3f8340aa916413eb046a491f4a31f1e",
            "461c3c8a4f464000b90f9a93411d5e17",
            "5b647adde5624154be2d67a697167fc8",
            "deb9bdac00864a238c392c29d531443b",
            "3e5e5111c2d54a46a69d53c665bcac2f",
            "4f3f09e7978c41a199ec0b067c14fd1a",
            "2d4aeff0203a42ad8a720713bf8dfa17",
            "df420756b86945ce8aec67d820d5a818",
            "a3f2bc987e164acab2c43baa70d49480",
            "e1a4168ed8f44d088cece38d8512af35",
            "19b25829032c4e268980e4dc5be6bbc5",
            "80d8294c691e46c3b99057b96c57637b",
            "fa91b29819a645dc86777cc75a2a6225",
            "c81d8610823649089355764bea3235e3",
            "2622c6e8312a4ba29b6c25fca8e387b1",
            "5090f8f19cf04fe68659c2f4fcdf74a2",
            "6539d61d53c7453daa422acb5c94f490",
            "b759602434294ddda8e4e34c4264a435",
            "69c4771b2481478e9c3dc4768991a817",
            "54964d97d5a0474e82f3c6001681b555"
          ]
        },
        "id": "7AeKVT25GWK7",
        "outputId": "d1c97492-13a4-4705-b544-711076b1aedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training with manual loop and early stopping...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/5 [Train]:   0%|          | 0/1908 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cd7cc4f30fb4b1db234204484e891e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/5 [Val]:   0%|          | 0/337 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e125396b17a4a48a83b3e6563f0abab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "  Train Loss: 0.2224, Acc: nan, F1: 0.0000\n",
            "  Val Loss: 0.1046, Acc: 0.9735, F1: 0.9741\n",
            "Sample batch predictions: [1 0 0 1 0 0 0 0 0 1]\n",
            "Sample batch labels: [1 0 0 1 0 0 0 0 0 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/5 [Train]:   0%|          | 0/1908 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1a4168ed8f44d088cece38d8512af35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n",
            "Unique predictions: [0 1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-fef863da0f31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting model training with manual loop and early stopping...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-2d1175af7498>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, lr)\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6e90625202ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (bs, seq_len, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (bs, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    794\u001b[0m                 )\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 )\n\u001b[1;32m    548\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    550\u001b[0m                     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mffn_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "print(\"Starting model training with manual loop and early stopping...\")\n",
        "model = train_model(model, train_dataloader, val_dataloader, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class weights:\", class_weights)  # Should be ~[0.93, 1.07]"
      ],
      "metadata": {
        "id": "gGiYN-iyM-Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.grad.abs().mean())  # Should not be all zeros"
      ],
      "metadata": {
        "id": "FI44NYmcNEpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train label distribution:\", train_df['label'].value_counts(normalize=True))\n",
        "print(\"Val label distribution:\", val_df['label'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "A6XZ-FlgNF5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_dataloader))\n",
        "print(\"Input IDs shape:\", sample['input_ids'].shape)\n",
        "print(\"Labels:\", sample['labels'].unique())"
      ],
      "metadata": {
        "id": "BJMVYCdpNnpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbqgFn6GWK7"
      },
      "source": [
        "### Calibrate classification threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ympdj6YNGWK7"
      },
      "outputs": [],
      "source": [
        "def calibrate_threshold(model, dataloader):\n",
        "    \"\"\"Find optimal classification threshold using precision-recall curve\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Calibrating threshold\"):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Prob of class 1 (fake)\n",
        "\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    # Find optimal threshold\n",
        "    precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)\n",
        "    f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    # Get the index of the best F1 score\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    # Get the threshold that gives the best F1 score\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    return optimal_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znCP9kKGGWK8"
      },
      "outputs": [],
      "source": [
        "# Calibrate threshold on validation set\n",
        "optimal_threshold = calibrate_threshold(model, val_dataloader)\n",
        "print(f\"Optimal classification threshold: {optimal_threshold:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qhFXzwP3Nir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmN2fcOlgHSH"
      },
      "source": [
        "## Results and Evaluation\n",
        "\n",
        "Assessing model performance on the test set with standard classification metrics:\n",
        "- Accuracy\n",
        "- Precision and recall\n",
        "- F1 score\n",
        "- Confusion matrix visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBTcP_kKgHSH"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, threshold=0.5):\n",
        "    \"\"\"Evaluate model with calibrated threshold\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_probs = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Prob of class 1 (fake)\n",
        "\n",
        "            # Apply threshold\n",
        "            preds = (probs >= threshold).astype(int)\n",
        "\n",
        "            all_probs.extend(probs)\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'probabilities': all_probs,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQhVh3MGWK8"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set with calibrated threshold\n",
        "test_results = evaluate_model(model, test_dataloader, threshold=optimal_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7l6iznRGWK8"
      },
      "outputs": [],
      "source": [
        "print(f\"Test Results (with threshold {optimal_threshold:.4f}):\")\n",
        "print(f\"Accuracy: {test_results['accuracy']:.4f}\")\n",
        "print(f\"Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"F1 Score: {test_results['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH77ronoGWK8"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = test_results['confusion_matrix']\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title(f'Confusion Matrix (Threshold: {optimal_threshold:.4f})')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwnBHOG4GWK8"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_results['labels'], test_results['predictions'], target_names=['Real', 'Fake']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lp4Hcr5gHSI"
      },
      "outputs": [],
      "source": [
        "def analyze_title(title, model, tokenizer, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Analyze a news title using the trained model\n",
        "\n",
        "    Args:\n",
        "        title: The news title to analyze\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        threshold: Classification threshold\n",
        "\n",
        "    Returns:\n",
        "        dict: Analysis results\n",
        "    \"\"\"\n",
        "    # Preprocess text\n",
        "    processed_title = preprocess_text(title)\n",
        "\n",
        "    # Tokenize\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    encoded_input = tokenizer(\n",
        "        processed_title,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
        "\n",
        "    # Get prediction\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(encoded_input['input_ids'], encoded_input['attention_mask'])\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    fake_prob = probs[0, 1].item()\n",
        "    real_prob = probs[0, 0].item()\n",
        "    prediction = \"Fake\" if fake_prob >= threshold else \"Real\"\n",
        "    processing_time = time.time() - start_time\n",
        "\n",
        "    # Calculate credibility score (inverted fake probability)\n",
        "    credibility_score = 1.0 - fake_prob\n",
        "\n",
        "    # Determine category\n",
        "    if credibility_score > 0.8:\n",
        "        category = \"credible\"\n",
        "    elif credibility_score < 0.2:\n",
        "        category = \"fake\"\n",
        "    else:\n",
        "        category = \"mixed\"\n",
        "\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"prediction\": prediction,\n",
        "        \"fake_probability\": fake_prob,\n",
        "        \"real_probability\": real_prob,\n",
        "        \"credibility_score\": credibility_score,\n",
        "        \"category\": category,\n",
        "        \"processing_time\": processing_time\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOklaX-1GWK8"
      },
      "outputs": [],
      "source": [
        "# Test the model with some examples\n",
        "test_titles = [\n",
        "    \"Scientists discover breakthrough treatment for cancer that pharmaceutical companies don't want you to know about.\",\n",
        "    \"According to a study published in the Journal of Medicine, regular exercise may reduce the risk of heart disease.\",\n",
        "    \"Secret government documents reveal aliens have been living among us for decades.\",\n",
        "    \"The Supreme Court announced its decision on the case yesterday, with a 6-3 majority opinion.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbK1kGxIGWK8"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTesting model on example titles:\")\n",
        "for title in test_titles:\n",
        "    result = analyze_title(title, model, tokenizer, threshold=optimal_threshold)\n",
        "    print(f\"\\nTitle: {result['title']}\")\n",
        "    print(f\"Prediction: {result['prediction']} (confidence: {max(result['fake_probability'], result['real_probability']):.4f})\")\n",
        "    print(f\"Category: {result['category']}\")\n",
        "    print(f\"Credibility score: {result['credibility_score']:.4f}\")\n",
        "    print(f\"Processing time: {result['processing_time']:.4f} seconds\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eambQlyaGWK8"
      },
      "outputs": [],
      "source": [
        "# Save the model and tokenizer\n",
        "MODEL_OUTPUT_DIR = \"./models/distilbert_titles_only\"\n",
        "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "torch.save(model.state_dict(), os.path.join(MODEL_OUTPUT_DIR, \"model.pt\"))\n",
        "tokenizer.save_pretrained(MODEL_OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3BiA9biGWK8"
      },
      "outputs": [],
      "source": [
        "# Save evaluation metrics\n",
        "metrics = {\n",
        "    \"model_name\": \"DistilBERT (Titles Only)\",\n",
        "    \"accuracy\": float(test_results['accuracy']),\n",
        "    \"precision\": float(test_results['precision']),\n",
        "    \"recall\": float(test_results['recall']),\n",
        "    \"f1_score\": float(test_results['f1']),\n",
        "    \"optimal_threshold\": float(optimal_threshold),\n",
        "    \"train_size\": len(train_df),\n",
        "    \"val_size\": len(val_df),\n",
        "    \"test_size\": len(test_df)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcIUISSxGWK9"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(MODEL_OUTPUT_DIR, \"metrics.json\"), \"w\") as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "print(f\"\\nModel saved to {MODEL_OUTPUT_DIR}\")\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cd7cc4f30fb4b1db234204484e891e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6981aa298cdc4f13a757f61af0054762",
              "IPY_MODEL_f41987886cd145b4b5a864839337fd86",
              "IPY_MODEL_ba5ae5c4849749f9a5e797934226fdb7"
            ],
            "layout": "IPY_MODEL_5efc3688e8ae4de4a6b14ef12addea65"
          }
        },
        "6981aa298cdc4f13a757f61af0054762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510ec59810d94a4bac199bfbeeedf000",
            "placeholder": "​",
            "style": "IPY_MODEL_89721b9ce0144a478e046a795249db55",
            "value": "Epoch 1/5 [Train]: 100%"
          }
        },
        "f41987886cd145b4b5a864839337fd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bb76f8b5af4716955adf1a9e3ae08b",
            "max": 1908,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a467cdde01c5432096172c4826c89c67",
            "value": 1908
          }
        },
        "ba5ae5c4849749f9a5e797934226fdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8411fe68bf9430f93eb1fb85226ea95",
            "placeholder": "​",
            "style": "IPY_MODEL_04ff2ae881bc4d4390ddff23fa9acdbd",
            "value": " 1908/1908 [01:53&lt;00:00, 16.29it/s]"
          }
        },
        "5efc3688e8ae4de4a6b14ef12addea65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510ec59810d94a4bac199bfbeeedf000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89721b9ce0144a478e046a795249db55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0bb76f8b5af4716955adf1a9e3ae08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a467cdde01c5432096172c4826c89c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8411fe68bf9430f93eb1fb85226ea95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ff2ae881bc4d4390ddff23fa9acdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e125396b17a4a48a83b3e6563f0abab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06190b12d435418cbe5717cb484dccc6",
              "IPY_MODEL_f3f8340aa916413eb046a491f4a31f1e",
              "IPY_MODEL_461c3c8a4f464000b90f9a93411d5e17"
            ],
            "layout": "IPY_MODEL_5b647adde5624154be2d67a697167fc8"
          }
        },
        "06190b12d435418cbe5717cb484dccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb9bdac00864a238c392c29d531443b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e5e5111c2d54a46a69d53c665bcac2f",
            "value": "Epoch 1/5 [Val]: 100%"
          }
        },
        "f3f8340aa916413eb046a491f4a31f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3f09e7978c41a199ec0b067c14fd1a",
            "max": 337,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d4aeff0203a42ad8a720713bf8dfa17",
            "value": 337
          }
        },
        "461c3c8a4f464000b90f9a93411d5e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df420756b86945ce8aec67d820d5a818",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f2bc987e164acab2c43baa70d49480",
            "value": " 337/337 [00:06&lt;00:00, 56.08it/s]"
          }
        },
        "5b647adde5624154be2d67a697167fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb9bdac00864a238c392c29d531443b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5e5111c2d54a46a69d53c665bcac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f3f09e7978c41a199ec0b067c14fd1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4aeff0203a42ad8a720713bf8dfa17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df420756b86945ce8aec67d820d5a818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f2bc987e164acab2c43baa70d49480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1a4168ed8f44d088cece38d8512af35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19b25829032c4e268980e4dc5be6bbc5",
              "IPY_MODEL_80d8294c691e46c3b99057b96c57637b",
              "IPY_MODEL_fa91b29819a645dc86777cc75a2a6225"
            ],
            "layout": "IPY_MODEL_c81d8610823649089355764bea3235e3"
          }
        },
        "19b25829032c4e268980e4dc5be6bbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2622c6e8312a4ba29b6c25fca8e387b1",
            "placeholder": "​",
            "style": "IPY_MODEL_5090f8f19cf04fe68659c2f4fcdf74a2",
            "value": "Epoch 2/5 [Train]:   7%"
          }
        },
        "80d8294c691e46c3b99057b96c57637b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6539d61d53c7453daa422acb5c94f490",
            "max": 1908,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b759602434294ddda8e4e34c4264a435",
            "value": 129
          }
        },
        "fa91b29819a645dc86777cc75a2a6225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c4771b2481478e9c3dc4768991a817",
            "placeholder": "​",
            "style": "IPY_MODEL_54964d97d5a0474e82f3c6001681b555",
            "value": " 129/1908 [00:07&lt;01:37, 18.33it/s]"
          }
        },
        "c81d8610823649089355764bea3235e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2622c6e8312a4ba29b6c25fca8e387b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5090f8f19cf04fe68659c2f4fcdf74a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6539d61d53c7453daa422acb5c94f490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b759602434294ddda8e4e34c4264a435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69c4771b2481478e9c3dc4768991a817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54964d97d5a0474e82f3c6001681b555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}