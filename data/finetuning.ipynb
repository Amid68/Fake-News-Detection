{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection - Alternative Training Approaches\n",
    "\n",
    "This notebook demonstrates two ways to finetune a lightweight transformer model for fake news detection:\n",
    "1. **Option A**: Using Hugging Face's Trainer API (requires installing accelerate)\n",
    "2. **Option B**: Using a manual PyTorch training loop (no accelerate dependency)\n",
    "\n",
    "Both approaches will produce similar results, but the manual loop gives you more control and fewer dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/miniconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (6.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch) (75.8.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.8.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n"
     ]
    }
   ],
   "source": [
    "# Base dependencies for both approaches\n",
    "!pip install torch transformers datasets scikit-learn pandas numpy matplotlib seaborn psutil tqdm\n",
    "\n",
    "# If you want to use Option A (Trainer API), also install accelerate:\n",
    "# Uncomment the line below to install it\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import psutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the FakeNewsNet Dataset (CSV Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake news dataset shape: (23481, 4)\n",
      "Real news dataset shape: (21417, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    fake_news = pd.read_csv(\"./fake-news-net/Fake.csv\")\n",
    "    real_news = pd.read_csv(\"./fake-news-net/True.csv\")\n",
    "    \n",
    "    print(f\"Fake news dataset shape: {fake_news.shape}\")\n",
    "    print(f\"Real news dataset shape: {real_news.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Please ensure the CSV files are in the correct location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake news dataset columns:\n",
      "['title', 'text', 'subject', 'date']\n",
      "\n",
      "Real news dataset columns:\n",
      "['title', 'text', 'subject', 'date']\n",
      "Sample from fake news dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from real news dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the datasets\n",
    "print(\"Fake news dataset columns:\")\n",
    "print(fake_news.columns.tolist())\n",
    "\n",
    "print(\"\\nReal news dataset columns:\")\n",
    "print(real_news.columns.tolist())\n",
    "\n",
    "# Display a few examples from each dataset\n",
    "print(\"Sample from fake news dataset:\")\n",
    "display(fake_news.head(2))\n",
    "\n",
    "print(\"\\nSample from real news dataset:\")\n",
    "display(real_news.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (44898, 5)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "1    23481\n",
      "0    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare combined dataset with labels\n",
    "# Add a label column (1 for fake, 0 for real)\n",
    "fake_news['label'] = 1\n",
    "real_news['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([fake_news, real_news], ignore_index=True)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {df.shape}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: title\n",
      "Example: Ben Stein Calls Out 9th Circuit Court: Committed a ‘Coup d’état’ Against the Constitution...\n",
      "Average length: 80.11 characters\n",
      "--------------------------------------------------\n",
      "Column: text\n",
      "Example: 21st Century Wire says Ben Stein, reputable professor from, Pepperdine University (also of some Holl...\n",
      "Average length: 2469.11 characters\n",
      "--------------------------------------------------\n",
      "Column: subject\n",
      "Example: US_News...\n",
      "Average length: 8.80 characters\n",
      "--------------------------------------------------\n",
      "Column: date\n",
      "Example: February 13, 2017...\n",
      "Average length: 14.83 characters\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect dataset columns to find title and text columns\n",
    "for col in df.columns:\n",
    "    if col != 'label':\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"Example: {df[col].iloc[0][:100]}...\")\n",
    "        print(f\"Average length: {df[col].str.len().mean():.2f} characters\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty texts after preprocessing: 9\n",
      "Dataset size after removing empty texts: 44889\n",
      "\n",
      "Sample processed text:\n",
      "ben stein calls out 9th circuit court: committed a ‘coup d’état’ against the constitution 21st century wire says ben stein, reputable professor from, pepperdine university (also of some hollywood fame appearing in tv shows and films such as ferris bueller s day off) made some provocative statements  ...\n"
     ]
    }
   ],
   "source": [
    "# Basic text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text data\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Based on the dataset inspection, combine title and text\n",
    "# Adjust these column names if needed according to your dataset structure\n",
    "title_col = 'title' if 'title' in df.columns else None\n",
    "text_col = 'text' if 'text' in df.columns else None\n",
    "\n",
    "# Combine and preprocess\n",
    "if title_col and text_col:\n",
    "    df['combined_text'] = df[title_col].fillna('') + ' ' + df[text_col].fillna('')\n",
    "elif title_col:\n",
    "    df['combined_text'] = df[title_col].fillna('')\n",
    "elif text_col:\n",
    "    df['combined_text'] = df[text_col].fillna('')\n",
    "else:\n",
    "    # If column names are different, choose the appropriate columns\n",
    "    # This is a fallback assuming the first non-label column is the text\n",
    "    text_columns = [col for col in df.columns if col != 'label']\n",
    "    if text_columns:\n",
    "        df['combined_text'] = df[text_columns[0]].fillna('')\n",
    "    else:\n",
    "        raise ValueError(\"No text columns found in the dataset\")\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_text'] = df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "# Check for empty texts after preprocessing\n",
    "empty_texts = df['processed_text'].apply(lambda x: len(x.strip()) == 0).sum()\n",
    "print(f\"Number of empty texts after preprocessing: {empty_texts}\")\n",
    "\n",
    "# Remove empty texts if any\n",
    "if empty_texts > 0:\n",
    "    df = df[df['processed_text'].apply(lambda x: len(x.strip()) > 0)].reset_index(drop=True)\n",
    "    print(f\"Dataset size after removing empty texts: {len(df)}\")\n",
    "\n",
    "# Display a sample preprocessed text\n",
    "print(\"\\nSample processed text:\")\n",
    "print(df['processed_text'].iloc[0][:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Data into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 30524\n",
      "Validation set size: 5387\n",
      "Test set size: 8978\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=SEED, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Then split train+val into train and validation\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, test_size=0.15, random_state=SEED, stratify=train_val_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Convert to tensors and remove batch dimension the tokenizer adds\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FakeNewsDataset(\n",
    "    train_df['processed_text'].tolist(),\n",
    "    train_df['label'].tolist(),\n",
    "    tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "val_dataset = FakeNewsDataset(\n",
    "    val_df['processed_text'].tolist(),\n",
    "    val_df['label'].tolist(),\n",
    "    tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "test_dataset = FakeNewsDataset(\n",
    "    test_df['processed_text'].tolist(),\n",
    "    test_df['label'].tolist(),\n",
    "    tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: distilbert-base-uncased\n",
      "Number of parameters: 66955010\n"
     ]
    }
   ],
   "source": [
    "# Load model for binary classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION A: Train with Hugging Face Trainer API\n",
    "\n",
    "**Note**: This requires the `accelerate` library. If you encounter errors, try OPTION B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`\n",
      "Please install the accelerate library with: pip install accelerate\n",
      "Alternatively, use Option B with manual training loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Only run this cell if you have accelerate installed\n",
    "try:\n",
    "    from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "    \n",
    "    def compute_metrics(pred):\n",
    "        \"\"\"\n",
    "        Compute metrics for evaluation.\n",
    "        \"\"\"\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results_distilbert',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs_distilbert',\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting model training with Trainer API...\")\n",
    "    train_start = time.time()\n",
    "    trainer.train()\n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    print(f\"Training completed in {train_time:.2f} seconds ({train_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    results = trainer.evaluate(test_dataset)\n",
    "    print(\"Test results:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "        \n",
    "    # Save model\n",
    "    MODEL_OUTPUT_DIR = \"./models/distilbert_fakenewsnet\"\n",
    "    trainer.save_model(MODEL_OUTPUT_DIR)\n",
    "    tokenizer.save_pretrained(MODEL_OUTPUT_DIR)\n",
    "    print(f\"Model saved to {MODEL_OUTPUT_DIR}\")\n",
    "    \n",
    "    # Success flag for Option A\n",
    "    option_a_success = True\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please install the accelerate library with: pip install accelerate\")\n",
    "    print(\"Alternatively, use Option B with manual training loop.\")\n",
    "    option_a_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION B: Train with Manual PyTorch Training Loop\n",
    "\n",
    "This approach doesn't require the `accelerate` library and gives you more control over the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "total_steps = len(train_dataloader) * 3  # 3 epochs\n",
    "warmup_steps = 500\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=5e-5, \n",
    "    total_steps=total_steps,\n",
    "    pct_start=warmup_steps/total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            labs = labels.cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training with manual training loop...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ebc66e691e4f7eb50ba853c8725010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3816 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "best_val_f1 = 0\n",
    "train_losses = []\n",
    "val_metrics = []\n",
    "\n",
    "# Skip training if Option A was successful\n",
    "if 'option_a_success' in locals() and option_a_success:\n",
    "    print(\"Skipping manual training loop since Option A (Trainer API) was successful.\")\n",
    "else:\n",
    "    print(\"Starting model training with manual training loop...\")\n",
    "    train_start = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        val_results = evaluate(model, val_dataloader, device)\n",
    "        val_metrics.append(val_results)\n",
    "        print(f\"Validation loss: {val_results['loss']:.4f}\")\n",
    "        print(f\"Validation accuracy: {val_results['accuracy']:.4f}\")\n",
    "        print(f\"Validation F1: {val_results['f1']:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_results['f1'] > best_val_f1:\n",
    "            best_val_f1 = val_results['f1']\n",
    "            MODEL_OUTPUT_DIR = \"./models/distilbert_fakenewsnet_manual\"\n",
    "            os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_OUTPUT_DIR, \"pytorch_model.bin\"))\n",
    "            tokenizer.save_pretrained(MODEL_OUTPUT_DIR)\n",
    "            print(f\"Saved new best model with F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    print(f\"Training completed in {train_time:.2f} seconds ({train_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_OUTPUT_DIR, \"pytorch_model.bin\")))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    test_results = evaluate(model, test_dataloader, device)\n",
    "    print(\"Test results:\")\n",
    "    for key, value in test_results.items():\n",
    "        if key not in ['predictions', 'labels']:\n",
    "            print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test results and confusion matrix\n",
    "# Try to use results from Option A if available, otherwise use Option B results\n",
    "if 'option_a_success' in locals() and option_a_success and 'results' in locals():\n",
    "    # Option A results (from Trainer)\n",
    "    test_pred_output = trainer.predict(test_dataset)\n",
    "    test_preds = test_pred_output.predictions.argmax(-1)\n",
    "    test_labels = test_pred_output.label_ids\n",
    "    test_metrics = {}\n",
    "    for key, value in results.items():\n",
    "        if key.startswith('eval_'):\n",
    "            test_metrics[key.replace('eval_', '')] = value\n",
    "        else:\n",
    "            test_metrics[key] = value\n",
    "else:\n",
    "    # Option B results (from manual loop)\n",
    "    test_preds = test_results['predictions']\n",
    "    test_labels = test_results['labels']\n",
    "    test_metrics = {k: v for k, v in test_results.items() if k not in ['predictions', 'labels']}\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=['Real', 'Fake']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Memory Usage and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to measure memory usage\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 * 1024)\n",
    "\n",
    "# Load model for inference\n",
    "# Choose the model path based on which training option succeeded\n",
    "if 'option_a_success' in locals() and option_a_success:\n",
    "    MODEL_PATH = \"./models/distilbert_fakenewsnet\"\n",
    "else:\n",
    "    MODEL_PATH = \"./models/distilbert_fakenewsnet_manual\"\n",
    "\n",
    "# Create pipeline for inference\n",
    "from transformers import pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Memory before\n",
    "mem_before = get_memory_usage()\n",
    "\n",
    "# Measure inference time on sample texts\n",
    "sample_texts = test_df['processed_text'].head(50).tolist()\n",
    "start_time = time.time()\n",
    "for text in sample_texts:\n",
    "    _ = classifier(text[:512])\n",
    "end_time = time.time()\n",
    "\n",
    "# Memory after\n",
    "mem_after = get_memory_usage()\n",
    "mem_used = mem_after - mem_before\n",
    "\n",
    "avg_inference_time = (end_time - start_time) / len(sample_texts)\n",
    "\n",
    "print(f\"Average inference time: {avg_inference_time:.4f} seconds per sample\")\n",
    "print(f\"Memory usage during inference: {mem_used:.2f} MB\")\n",
    "\n",
    "# Add these to a metrics dictionary\n",
    "model_metrics = {\n",
    "    \"model_name\": \"DistilBERT\",\n",
    "    \"accuracy\": test_metrics.get('accuracy'),\n",
    "    \"f1_score\": test_metrics.get('f1'),\n",
    "    \"precision\": test_metrics.get('precision'),\n",
    "    \"recall\": test_metrics.get('recall'),\n",
    "    \"avg_processing_time\": avg_inference_time,\n",
    "    \"avg_memory_usage\": mem_used,\n",
    "    \"parameter_count\": sum(p.numel() for p in model.parameters())\n",
    "}\n",
    "\n",
    "# Save metrics\n",
    "METRICS_OUTPUT_PATH = \"./models/distilbert_fakenewsnet_metrics.json\"\n",
    "with open(METRICS_OUTPUT_PATH, 'w') as f:\n",
    "    json.dump(model_metrics, f, indent=4)\n",
    "print(f\"Model metrics saved to {METRICS_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test the Model with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a few examples\n",
    "examples = [\n",
    "    \"Scientists discover breakthrough treatment for cancer that pharmaceutical companies don't want you to know about.\",\n",
    "    \"According to a study published in the Journal of Medicine, regular exercise may reduce the risk of heart disease.\",\n",
    "    \"Secret government documents reveal aliens have been living among us for decades.\",\n",
    "    \"The Supreme Court announced its decision on the case yesterday, with a 6-3 majority opinion.\"\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    result = classifier(example)\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    \n",
    "    # Convert label index to text\n",
    "    label_text = \"Fake\" if \"LABEL_1\" in label else \"Real\"\n",
    "    \n",
    "    print(f\"Text: {example}\")\n",
    "    print(f\"Prediction: {label_text} (confidence: {score:.4f})\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Code for Django Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to integrate with Django (for services.py)\n",
    "def analyze_with_distilbert(text, model_dir=\"./models/distilbert_fakenewsnet\"):\n",
    "    \"\"\"\n",
    "    Analyze text using the trained DistilBERT model.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to analyze\n",
    "        model_dir: Path to the saved model directory\n",
    "        \n",
    "    Returns:\n",
    "        dict: Detection results\n",
    "    \"\"\"\n",
    "    # Import the required libraries (inside the function to avoid loading at startup)\n",
    "    import time\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    \n",
    "    # Determine device (CPU or GPU)\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    \n",
    "    # Create pipeline\n",
    "    classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, device=device)\n",
    "    \n",
    "    # Measure performance\n",
    "    start_time = time.time()\n",
    "    result = classifier(text[:512])[0]\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Map the result\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    \n",
    "    # In this model, LABEL_0 = real, LABEL_1 = fake\n",
    "    if \"LABEL_0\" in label:\n",
    "        credibility_score = score\n",
    "        category = \"credible\" if score > 0.7 else \"mixed\"\n",
    "    else:\n",
    "        credibility_score = 1 - score\n",
    "        category = \"fake\" if score > 0.7 else \"mixed\"\n",
    "    \n",
    "    return {\n",
    "        \"credibility_score\": credibility_score,\n",
    "        \"category\": category,\n",
    "        \"confidence\": score,\n",
    "        \"model_name\": \"DistilBERT\",\n",
    "        \"processing_time\": processing_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Integrating with Django\n",
    "\n",
    "To integrate this model with your Django application:\n",
    "\n",
    "1. Copy the trained model files to a directory accessible by your Django app\n",
    "2. Add the `analyze_with_distilbert` function to your `services.py` file\n",
    "3. Update your Django view to call this function:\n",
    "\n",
    "```python\n",
    "# In views.py\n",
    "from .services import analyze_with_distilbert\n",
    "\n",
    "def analyze_text_view(request):\n",
    "    \"\"\"View for analyzing custom text with the model.\"\"\"\n",
    "    results = None\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        text = request.POST.get('text', '')\n",
    "\n",
    "        if text:\n",
    "            # Path to your model directory\n",
    "            model_dir = \"path/to/your/models/distilbert_fakenewsnet\"\n",
    "            \n",
    "            # Analyze the text\n",
    "            results = analyze_with_distilbert(text, model_dir)\n",
    "\n",
    "    return render(request, 'news/analyze_text.html', {'results': results})\n",
    "```\n",
    "\n",
    "4. Update your template to display the results\n",
    "\n",
    "For production use, consider these optimizations:\n",
    "- Load the model once at startup rather than for every request\n",
    "- Use a worker process or Celery for asynchronous processing\n",
    "- Consider a smaller model for faster inference if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
